{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import os; from analysis_helpers import *; import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_logs(data_dir):\n",
    "    '''\n",
    "    input : path to participant data directory  (str)\n",
    "    output: participant's full behavioral log   (df)\n",
    "    '''\n",
    "            \n",
    "    participant = []\n",
    "    for f in os.listdir(data_dir):\n",
    "\n",
    "        if f !='--1.log' and ('.log' in f):\n",
    "\n",
    "            with open(data_dir+f) as file:\n",
    "\n",
    "                    lines = file.read().splitlines()\n",
    "                    lines = [[lines[x]] for x in range(0, len(lines))]\n",
    "                    #lines.insert(0,['DATA'])\n",
    "\n",
    "                    log_file = pd.DataFrame(lines).reset_index()\n",
    "\n",
    "                    log_file['Subject'] = sub_dir.split('_')[0]\n",
    "                    log_file['Run'] = int(f.split('.')[-2][-1])\n",
    "                    log_file['TIME'],log_file['WARNING'],log_file['MESSAGE'] = log_file[0].str.split('\\t', 4).str\n",
    "                    log_file = log_file.fillna('NAN VALUE')\n",
    "                    log_file['TIME'] = log_file['TIME'].str.replace(' ','')\n",
    "                    log_file['TIME'] = log_file['TIME'].astype(float, errors='ignore')\n",
    "\n",
    "                    a = log_file[log_file[0].str.contains('current')][0].str.split(' ', expand=True)\n",
    "                    log_file['TIME'] = log_file[['TIME']].applymap(lambda x: np.nan if isinstance(x, str) else float(x))\n",
    "                    #log_file['TIME'] = log_file['TIME'] + float(a[4]) - float(a[0])\n",
    "\n",
    "#                             utc = log_file[0].str.contains('current')['MESSAGE'].split(' ')[-1]\n",
    "#                             psycho = log_file[0].str.contains('current')['TIME']\n",
    "\n",
    "                    participant.append(log_file)\n",
    "\n",
    "    participant = pd.concat(participant)\n",
    "    return(participant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Compile\n",
    "Organize behavioral data from each participant into one dataframe for the whole experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../variable_attention_experiment/data/group1\n",
      "8_2019_Feb_28\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "15_2019_Apr_01\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "1_2019_Feb_21\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "25_2019_Apr_16\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "12_2019_Mar_27\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "4_2019_Feb_21\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "28_2019_Apr_23\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "19_2019_Apr_01\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "21_2019_Apr_09\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "33_2019_Apr_26\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "7_2019_Feb_28\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "26_2019_Apr_16\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "14_2019_Mar_29\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "2_2019_Feb_21\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "16_2019_Apr_01\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "27_2019_Apr_22\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "23_2019_Apr_10\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "18_2019_Apr_01\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "29_2019_Apr_23\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "13_2019_Mar_29\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "5_2019_Feb_26\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "24_2019_Apr_11\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "0_2019_Feb_21\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "34_2019_Apr_27\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "22_2019_Apr_10\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "327_2019_Mar_27\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "17_2019_Apr_01\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "3_2019_Feb_21\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "10_2019_Mar_27\n",
      "\n",
      "../variable_attention_experiment/data/group1\n",
      "20_2019_Apr_09\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "17_2019_Nov_18\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "12_2019_Nov_17\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "20_2019_Nov_19\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "2_2019_Nov_14\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "30_2020_Jan_13\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "25_2020_Jan_24\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "11_2019_Nov_17\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "18_2019_Nov_19\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "4_2019_Nov_14\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "9_2019_Nov_16\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "29_2020_Jan_13\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "14_2019_Nov_17\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "21_2019_Nov_19\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "27_2020_Jan_15\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "6_2019_Nov_15\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "16_2019_Nov_18\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "26_2020_Jan_16\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "28_2020_Jan_13\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "8_2019_Nov_16\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "15_2019_Nov_18\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "1_2019_Oct_26\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "5_2019_Nov_15\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "19_2019_Nov_19\n",
      "\n",
      "../variable_attention_experiment/data/group2\n",
      "10_2019_Nov_16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile data from all exps\n",
    "# add attention labels to memory stim\n",
    "# correct timings for group1 - safest estimate\n",
    "# check and add gaze data\n",
    "# output dataframe with attn labels, timing, and gaze data\n",
    "\n",
    "# run behavioral checks and further gaze checks\n",
    "\n",
    "a,b = '../sustained_attention_experiment/data/','../variable_attention_experiment/data/'\n",
    "# data_dirs = [a+'group1', a+'group2', b+'group1', b+'group2']\n",
    "data_dirs = [b+'group1', b+'group2']\n",
    "filenames = [x+'_partial_new.csv' for x in data_dirs]\n",
    "\n",
    "for data,file in zip(data_dirs, filenames):\n",
    "    \n",
    "    sub_list = []\n",
    "    \n",
    "    # for each subject in this directory\n",
    "    for sub_dir in os.listdir(data):\n",
    "        \n",
    "        if sub_dir != '.DS_Store' and sub_dir != 'README.md':\n",
    "            \n",
    "            print(data)\n",
    "            print(sub_dir)\n",
    "            print()\n",
    "            \n",
    "            # add attention labels to memory stim \n",
    "            subject = add_level(sum_pd(data + '/' + sub_dir))\n",
    "            \n",
    "            # TIMING CORRRECTIONS (for gaze)\n",
    "            if data[-1] == '1':\n",
    "               \n",
    "                # github Issue #83, Check B: times in behavioral csv's (Group1) imprecise by fractions of a second\n",
    "                # correct for those timing issues (for gaze analysis), using safest estimates \n",
    "                \n",
    "                # SUSTAINED: cued composite starts .0178 seconds earlier; VAR : .0167 earlier \n",
    "                # SUSTAINED: composites disappear 0.0322 secs later; VARIABLE: .0359 secs \n",
    "                subject.loc[subject['Trial Type']=='Presentation','Stimulus Onset'] = subject[subject['Trial Type']=='Presentation']['Stimulus Onset'] - .0178\n",
    "                subject.loc[subject['Trial Type']=='Presentation','Stimulus End']   = subject[subject['Trial Type']=='Presentation']['Stimulus End']   + .0359\n",
    "                  \n",
    "                # SUST: mem images display 0.0179 earlier; VAR: .0142\n",
    "                # SUST: mem images disappear .259 secs later; VAR: .137\n",
    "                subject.loc[subject['Trial Type']=='Memory','Stimulus Onset'] = subject[subject['Trial Type']=='Memory']['Stimulus Onset'] - .0179\n",
    "                subject.loc[subject['Trial Type']=='Memory','Stimulus End']   = subject[subject['Trial Type']=='Memory']['Stimulus End']   +.259\n",
    "                \n",
    "                # NOTE: no correction for button press differences, as they averaged .001 seconds or less\n",
    "\n",
    "                \n",
    "                if data == '../variable_attention_experiment/data/group1':\n",
    "                \n",
    "                    # EXP 2 cue corrections ---------------\n",
    "                    # github Issue #83, Check E: some Group1, Var Exp valid cues marked as invalid\n",
    "                    \n",
    "                    # correct cue labels Var Exp, Group 1\n",
    "                    for run in subject['Run'].unique():\n",
    "                        first_cue = list(subject[(subject['Run']==run) & (subject['Trial Type']=='Presentation')]['Cued Side'])\n",
    "                        if subject[(subject['Run']==run) & (subject['Cue Validity']==0) & (subject['Cued Side'] != first_cue[0])].shape[0]>0:\n",
    "                            subject.loc[(subject['Run']==run) & (subject['Cue Validity']==0) & (subject['Cued Side'] != first_cue[0]), 'Cue Validity'] = 1\n",
    "                        \n",
    "                        \n",
    "            if data[-1] == '2':\n",
    "                subject_log = list_logs(data + '/' + sub_dir+'/')\n",
    "                subject_log['Subject'] = pd.to_numeric(subject_log['Subject'])\n",
    "                subject_log = subject_log.sort_values(by=['Subject','Run','TIME'])\n",
    "                subject = subject.sort_values(by=['Subject','Run'])\n",
    "                \n",
    "                # now, extract desired stim on and off times\n",
    "                composite_onsets  = subject_log[subject_log[0].str.contains('COMPOSITES ON')]\n",
    "                composite_offsets = subject_log[subject_log[0].str.contains('COMPOSITES OFF')]\n",
    "                attention_on = composite_offsets \n",
    "                \n",
    "                subject.loc[subject['Trial Type']=='Presentation', 'Stimulus Onset'] = list(composite_onsets['TIME'])\n",
    "                subject.loc[subject['Trial Type']=='Presentation', 'Stimulus End'  ] = list(composite_offsets['TIME'])\n",
    "                subject.loc[subject['Trial Type']=='Presentation','Attention Response Time (s)'] = subject[subject['Trial Type']=='Presentation']['Attention Response Time (s)'] - subject[subject['Trial Type']=='Presentation']['Stimulus End']\n",
    "                \n",
    "                memory_onsets  = list(subject_log[ (subject_log[0].str.contains('MEMORY ON')) & (subject_log[0].str.contains('FLIP')) ]['TIME'])\n",
    "                memory_offsets = list(subject_log[ (subject_log[0].str.contains('MEMORY OFF')) & (subject_log[0].str.contains('FLIP')) ]['TIME'])\n",
    "                \n",
    "                subject.loc[subject['Trial Type']=='Memory', 'Stimulus Onset'] = memory_onsets\n",
    "                subject.loc[subject['Trial Type']=='Memory', 'Stimulus End'  ] = memory_offsets\n",
    "                \n",
    "            # add ON and OFF stim times for group 2\n",
    "                \n",
    "                \n",
    "            # GROUP 2 -- attention probe reaction time conversions\n",
    "                \n",
    "                # attention reaction times pulled from log file use psychopy timeline\n",
    "                # switching to time from stim onset (reaction time)\n",
    "                \n",
    "                \n",
    "            # Add gaze data (internal)\n",
    "            # renumber the subject (internal)\n",
    "                \n",
    "\n",
    "            sub_list.append(subject)\n",
    "                \n",
    "            \n",
    "    exp_raw = pd.concat(sub_list)\n",
    "    exp_raw.to_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composite_onsets['Run'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 26)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject.loc[(subject['Run']==run) & (subject['Cue Validity']==0) & (subject['Cued Side'] != first_cue)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the behavioral and gaze data for both exps, Groups 1 and 2\n",
    "\n",
    "    # for each subj:\n",
    "        \n",
    "        # compile behavioral\n",
    "        \n",
    "            # pull from log files and convert times as needed\n",
    "        \n",
    "        # check gaze data (file for each, data for all times needed, units, etc)\n",
    "        \n",
    "        # check for redundancies\n",
    "        \n",
    "        # do gaze calcs and add to dataframe\n",
    "        \n",
    "        \n",
    "        # save out compiled full csv in this subject's dir (under temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # GROUP 2 -- attention probe reaction time conversions\n",
    "            if data_dirs[-1] == '2':\n",
    "                \n",
    "                # attention reaction times pulled from log file use psychopy timeline\n",
    "                # switching to time from stim onset (reaction time)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../sustained_attention_experiment/data/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3a1af8cd6477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msub_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0msub_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_pd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mexp_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/data_add_only/attention-memory-task/data_analysis_code/analysis_helpers.py\u001b[0m in \u001b[0;36msum_pd\u001b[0;34m(subdir)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# list all files in the subject's directory that contain pres or mem run data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'pres'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'mem'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# read in the data from each of these files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../sustained_attention_experiment/data/.DS_Store'"
     ]
    }
   ],
   "source": [
    "# Compile the behavioral data for both exps, Groups 1 and 2\n",
    "\n",
    "# Complete all necessary checks\n",
    "\n",
    "# \n",
    "\n",
    "# Produce a single dataframe with all of the necessary data, labeled by: \n",
    "# experiment and group number\n",
    "\n",
    "\n",
    "\n",
    "data_dirs = ['../sustained_attention_experiment/data',\n",
    "             '../variable_attention_experiment/data',\n",
    "            '',\n",
    "            '']\n",
    "\n",
    "\n",
    "\n",
    "filenames = ['../parsed_data/behavioral_data_sustained.csv', \n",
    "             '../parsed_data/behavioral_data_variable.csv']\n",
    "\n",
    "for data,file in zip(data_dirs, filenames):\n",
    "    \n",
    "    sub_list = []\n",
    "    \n",
    "    for sub_dir in os.listdir(data):\n",
    "        sub_list.append(add_level(sum_pd(data + '/' + sub_dir)))\n",
    "\n",
    "    exp_raw = pd.concat(sub_list)\n",
    "    exp_raw.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
