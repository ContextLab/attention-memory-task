{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import seaborn as sb; import warnings; import scipy; import re; \n",
    "import os; from analysis_helpers import *; import itertools; from scipy import stats\n",
    "import random; import pandas as pd; import numpy as np; from sklearn import datasets, linear_model; \n",
    "from sklearn.linear_model import LinearRegression; import statsmodels.api as sm\n",
    "from scipy import stats; from itertools import groupby; from operator import itemgetter\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check A:  loading behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../sustained_attention_experiment/data/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e11a77fbe3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# aggregate all the data from the participant into a dataframe, and append to a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msub_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_pd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'We have loaded data from {len(sub_list)} unique subjects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/data_add_only/attention-memory-task/data_analysis_code/analysis_helpers.py\u001b[0m in \u001b[0;36msum_pd\u001b[0;34m(subdir)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# list all files in the subject's directory that contain pres or mem run data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'pres'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'mem'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# read in the data from each of these files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../sustained_attention_experiment/data/.DS_Store'"
     ]
    }
   ],
   "source": [
    "# for each experiment's data directory\n",
    "for data_dir in ['../sustained_attention_experiment/data', '../variable_attention_experiment/data']:\n",
    "    \n",
    "    sub_list = []\n",
    "\n",
    "    # for each participant directory in the data directory\n",
    "    for sub_dir in os.listdir(data_dir):\n",
    "        \n",
    "        # aggregate all the data from the participant into a dataframe, and append to a list\n",
    "        sub_list.append(sum_pd(data_dir + '/' + sub_dir))\n",
    "\n",
    "    print(f'We have loaded data from {len(sub_list)} unique subjects')\n",
    "\n",
    "    ############################################\n",
    "\n",
    "    # Concatenate the list into single dataframe \n",
    "    concatenated = pd.concat(sub_list)\n",
    "    \n",
    "    # obtain the number of unique runs for each participant for each trial type (Presentation and Memory)\n",
    "    unique_runs = concatenated.groupby(['Subject','Trial Type'])['Run'].nunique()\n",
    "    \n",
    "    print()\n",
    "    print('Below, we can see the number of unique runs loaded for each subject, for each trial type.')\n",
    "    print()\n",
    "    print('The set of all numbers of runs from all participants contains '\n",
    "          + str(unique_runs.nunique()) + ' unique value: '+str(unique_runs.unique()))\n",
    "    print()\n",
    "    print(str(unique_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check B1: check attention level assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in labeled data\n",
    "exp1 = pd.read_csv('../parsed_data/behavioral_data_sustained.csv')\n",
    "exp2 = pd.read_csv('../parsed_data/behavioral_data_variable.csv')\n",
    "\n",
    "\n",
    "# label rows by trial number\n",
    "# see the check in issue #83, where we confirm that all rows are in the temporal order from the experiment \n",
    "# (early trials at the top, late trials at the bottom)\n",
    "for exp in [exp1, exp2]:\n",
    "\n",
    "    # Number all presentation and memory trials \n",
    "    exp.loc[exp['Trial Type']=='Memory','Trial'] = list(range(0,40))*30*8\n",
    "    exp.loc[exp['Trial Type']=='Presentation','Trial'] = list(range(0,10))*30*8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check B1a: Number of images at each attention level, in each memory run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each experiment\n",
    "for exp in [exp1, exp2]:\n",
    "      \n",
    "    # number of unique images at each attention level (prev-seen images and Novel images)\n",
    "    unique_seen  = exp[exp['Attention Level']!='Novel'].groupby(['Subject','Run', 'Attention Level'])['Trial'].nunique()\n",
    "    unique_novel = exp[exp['Attention Level']=='Novel'].groupby(['Subject','Run', 'Attention Level'])['Trial'].nunique()\n",
    "\n",
    "    for name,data in zip(['novel','previously seen'],[unique_novel, unique_seen]):\n",
    "\n",
    "        print('The set of the numbers of ' + name + ' images from each attention level, displayed to each participant, in each run, contains '+\n",
    "              str(data.nunique())+' unique value : '+str(data.unique()))\n",
    "        print()\n",
    "        print(data)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check B1b: Novel images equal proportion faces and places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novel Faces and Places\n",
    "for exp in [exp1, exp2]:\n",
    "    \n",
    "    # number of unique images at each attention level (prev-seen images and Novel images)\n",
    "    unique_novel = exp[exp['Attention Level']=='Novel'].groupby(['Subject','Run', 'Attention Level','Category'])['Trial'].nunique()\n",
    "\n",
    "    print('The set of the numbers of Novel face images and Novel place images displayed to each participant, in each run, contains '+\n",
    "    str(unique_novel.nunique())+' unique value(s) : '+str(unique_novel.unique()))\n",
    "    \n",
    "    print()\n",
    "    print(unique_novel)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check B1c: \n",
    "###### Full  and  Category   images from each run are same image category\n",
    "###### Side  and   None       images from each run are same image category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check B2: Randomly select runs from random participants to spot check manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select two participants\n",
    "# randomly select a run from each participant's data\n",
    "# output randomly selected runs to html file for manual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-56f2cc947637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'exp2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Run'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp1' is not defined"
     ]
    }
   ],
   "source": [
    "for exp_name,exp,seed in zip(['exp1','exp2'],[exp1,exp2],[1,2]):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    sub = random.sample(list(exp['Subject'].unique()), 2)\n",
    "    run = random.sample(list(exp['Run'].unique()), 2)    \n",
    "\n",
    "    for s,r in zip(sub,run):\n",
    "        exp[(exp['Subject']==s) & (exp['Run']==r)].to_csv(exp_name+'_'+str(s)+'_'+str(r)+'_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
