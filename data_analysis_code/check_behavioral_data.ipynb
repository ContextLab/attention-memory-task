{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import seaborn as sb; import warnings; import scipy; import re; \n",
    "import os; from analysis_helpers import *; import itertools; from scipy import stats\n",
    "import random; import pandas as pd; import numpy as np; from sklearn import datasets, linear_model; \n",
    "from sklearn.linear_model import LinearRegression; import statsmodels.api as sm\n",
    "from scipy import stats; from itertools import groupby; from operator import itemgetter\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check A:  loading behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../sustained_attention_experiment/data/group1/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-22320b95b083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# aggregate all the data from the participant into a dataframe, and append to a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0msub_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_pd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Desktop-February/data_add_only/attention-memory-task/data_analysis_code/analysis_helpers.py\u001b[0m in \u001b[0;36msum_pd\u001b[0;34m(subdir)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# list all files in the subject's directory that contain pres or mem run data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'pres'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'mem'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# read in the data from each of these files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../sustained_attention_experiment/data/group1/.DS_Store'"
     ]
    }
   ],
   "source": [
    "# for each experiment's data directory\n",
    "for data_dir in ['../sustained_attention_experiment/data', '../variable_attention_experiment/data']:\n",
    "    \n",
    "    for group in ['group1', 'group2']:\n",
    "        \n",
    "        sub_list = []\n",
    "\n",
    "        # for each participant directory in the data directory\n",
    "        for sub_dir in os.listdir(data_dir+'/'+group):\n",
    "\n",
    "            # aggregate all the data from the participant into a dataframe, and append to a list\n",
    "            sub_list.append(sum_pd(data_dir + '/' + group + '/' + sub_dir))\n",
    "\n",
    "        print(data_dir)\n",
    "        print(group)\n",
    "            \n",
    "        print(f'We have loaded data from {len(sub_list)} unique subjects')\n",
    "\n",
    "        ############################################\n",
    "\n",
    "        # Concatenate the list into single dataframe \n",
    "        concatenated = pd.concat(sub_list)\n",
    "\n",
    "        # obtain the number of unique runs for each participant for each trial type (Presentation and Memory)\n",
    "        unique_runs = concatenated.groupby(['Subject','Trial Type'])['Run'].nunique()\n",
    "\n",
    "        print()\n",
    "        print('Below, we can see the number of unique runs loaded for each subject, for each trial type.')\n",
    "        print()\n",
    "        print('The set of all numbers of runs from all participants contains '\n",
    "              + str(unique_runs.nunique()) + ' unique value: '+str(unique_runs.unique()))\n",
    "        print()\n",
    "        print(str(unique_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check B1: check attention level assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in labeled data\n",
    "data = pd.read_csv('../parsed_data/full_behavioral.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check B1a: Number of images at each attention level, in each memory run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each experiment\n",
    "for subject in data['UniqueID'].unique():\n",
    "        \n",
    "    for run in data['Run'].unique():\n",
    "            \n",
    "              print(data[(data['UniqueID']==subject) & (data['Run']==run)\n",
    "                        & (data['Trial Type']=='Memory')].groupby(['Attention Level']).count()['Trial'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check B1b: Novel images equal proportion faces and places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each experiment\n",
    "count = 0\n",
    "for subject in data['UniqueID'].unique():\n",
    "        \n",
    "    for run in data['Run'].unique():\n",
    "            \n",
    "        print(data[(data['UniqueID']==subject) & (data['Run']==run)\n",
    "                & (data['Trial Type']=='Memory')\n",
    "                & (data['Attention Level']=='Novel')].groupby(['Category']).count()['Trial'])\n",
    "                \n",
    "        count+=1\n",
    "                \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check B1c: \n",
    "###### Full  and  Category   images from each run are same image category\n",
    "###### Side  and   None       images from each run are same image category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check B2: Randomly select runs from random participants to spot check manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select two participants\n",
    "# randomly select a run from each participant's data\n",
    "# output randomly selected runs to html file for manual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one participant from each experiment and group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Attention Cuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['combined_cue'] = data['Cued Category'] + data['Cued Side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "# for exp 1, look across blocks and make sure an even number of cues seen and no two back to back blocks with same cues\n",
    "data_1 = data[data['Experiment']=='/sustain']\n",
    "\n",
    "for sub in data_1['UniqueID'].unique():\n",
    "    for run in data_1['Run'].unique():\n",
    "        \n",
    "        cue_list = data_1[(data['Run']==run) & (data_1['UniqueID']==sub)].groupby(['Run'], as_index=False)['combined_cue']\n",
    "        cue_list = list(cue_list)\n",
    "        \n",
    "        for idx,x in enumerate(cue_list):\n",
    "            if idx != 0:\n",
    "                if x == cue_list[idx-1]:\n",
    "                    \n",
    "                    good = False\n",
    "                    print()\n",
    "                    print(\"Repeats present\")\n",
    "                    print('Subject ' + str(sub) + ' run ' + str(idx) + ' is a repeat cue.')\n",
    "                    \n",
    "                    \n",
    "\n",
    "# for exp 2, look within blocks and make sure no two cues seen back to back\n",
    "# look for even number of right and left, face and place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cue_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6f6322241704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcue_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cue_list' is not defined"
     ]
    }
   ],
   "source": [
    "cue_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
