{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 1,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
   "execution_count": 1,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
   "execution_count": 1,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import seaborn as sb; import warnings; import scipy; import re; \n",
    "import os; from analysis_helpers import *; import itertools; from scipy import stats\n",
    "import random; import pandas as pd; import numpy as np; from sklearn import datasets, linear_model; \n",
    "from sklearn.linear_model import LinearRegression; import statsmodels.api as sm\n",
    "from scipy import stats; from itertools import groupby; from operator import itemgetter\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "# Check A:  behavioral data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of output chunk, a statement indicates the number of participants and the unique number of presentation and memory behavioral file counts (for example, if all participants have 8 presentation and 8 memory runs, then this value will be '8'; if some participants have 8 files, and some have 7 -- missing a file -- then the numbers '7' and '8' will display; etc)."
=======
    "# Check A:  loading behavioral data"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
    "# Check A:  loading behavioral data"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
    "# Check A:  loading behavioral data"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../sustained_attention_experiment/data\n",
      "group1\n",
      "\n",
      "We have loaded data from 30 unique subjects\n",
      "\n",
      "Below, we can see the number of unique runs loaded for each subject, for each trial type.\n",
      "\n",
      "The set of all numbers of runs from all participants contains 1 unique value: [8]\n",
      "\n",
      "Subject  Trial Type  \n",
      "0        Memory          8\n",
      "         Presentation    8\n",
      "2        Memory          8\n",
      "         Presentation    8\n",
      "6        Memory          8\n",
      "         Presentation    8\n",
      "7        Memory          8\n",
      "         Presentation    8\n",
      "8        Memory          8\n",
      "         Presentation    8\n",
      "9        Memory          8\n",
      "         Presentation    8\n",
      "10       Memory          8\n",
      "         Presentation    8\n",
      "11       Memory          8\n",
      "         Presentation    8\n",
      "12       Memory          8\n",
      "         Presentation    8\n",
      "13       Memory          8\n",
      "         Presentation    8\n",
      "14       Memory          8\n",
      "         Presentation    8\n",
      "15       Memory          8\n",
      "         Presentation    8\n",
      "16       Memory          8\n",
      "         Presentation    8\n",
      "17       Memory          8\n",
      "         Presentation    8\n",
      "18       Memory          8\n",
      "         Presentation    8\n",
      "19       Memory          8\n",
      "         Presentation    8\n",
      "20       Memory          8\n",
      "         Presentation    8\n",
      "21       Memory          8\n",
      "         Presentation    8\n",
      "22       Memory          8\n",
      "         Presentation    8\n",
      "23       Memory          8\n",
      "         Presentation    8\n",
      "24       Memory          8\n",
      "         Presentation    8\n",
      "25       Memory          8\n",
      "         Presentation    8\n",
      "26       Memory          8\n",
      "         Presentation    8\n",
      "27       Memory          8\n",
      "         Presentation    8\n",
      "30       Memory          8\n",
      "         Presentation    8\n",
      "31       Memory          8\n",
      "         Presentation    8\n",
      "32       Memory          8\n",
      "         Presentation    8\n",
      "33       Memory          8\n",
      "         Presentation    8\n",
      "34       Memory          8\n",
      "         Presentation    8\n",
      "36       Memory          8\n",
      "         Presentation    8\n",
      "Name: Run, dtype: int64\n",
      "\n",
      "../sustained_attention_experiment/data\n",
      "group2\n",
      "\n",
      "We have loaded data from 30 unique subjects\n",
      "\n",
      "Below, we can see the number of unique runs loaded for each subject, for each trial type.\n",
      "\n",
      "The set of all numbers of runs from all participants contains 1 unique value: [8]\n",
      "\n",
      "Subject  Trial Type  \n",
      "0        Memory          8\n",
      "         Presentation    8\n",
      "1        Memory          8\n",
      "         Presentation    8\n",
      "2        Memory          8\n",
      "         Presentation    8\n",
      "3        Memory          8\n",
      "         Presentation    8\n",
      "4        Memory          8\n",
      "         Presentation    8\n",
      "5        Memory          8\n",
      "         Presentation    8\n",
      "7        Memory          8\n",
      "         Presentation    8\n",
      "8        Memory          8\n",
      "         Presentation    8\n",
      "9        Memory          8\n",
      "         Presentation    8\n",
      "10       Memory          8\n",
      "         Presentation    8\n",
      "11       Memory          8\n",
      "         Presentation    8\n",
      "13       Memory          8\n",
      "         Presentation    8\n",
      "14       Memory          8\n",
      "         Presentation    8\n",
      "15       Memory          8\n",
      "         Presentation    8\n",
      "16       Memory          8\n",
      "         Presentation    8\n",
      "18       Memory          8\n",
      "         Presentation    8\n",
      "19       Memory          8\n",
      "         Presentation    8\n",
      "20       Memory          8\n",
      "         Presentation    8\n",
      "25       Memory          8\n",
      "         Presentation    8\n",
      "28       Memory          8\n",
      "         Presentation    8\n",
      "32       Memory          8\n",
      "         Presentation    8\n",
      "34       Memory          8\n",
      "         Presentation    8\n",
      "35       Memory          8\n",
      "         Presentation    8\n",
      "36       Memory          8\n",
      "         Presentation    8\n",
      "38       Memory          8\n",
      "         Presentation    8\n",
      "39       Memory          8\n",
      "         Presentation    8\n",
      "40       Memory          8\n",
      "         Presentation    8\n",
      "Name: Run, dtype: int64\n",
      "\n",
      "../variable_attention_experiment/data\n",
      "group1\n",
      "\n",
      "We have loaded data from 30 unique subjects\n",
      "\n",
      "Below, we can see the number of unique runs loaded for each subject, for each trial type.\n",
      "\n",
      "The set of all numbers of runs from all participants contains 1 unique value: [8]\n",
      "\n",
      "Subject  Trial Type  \n",
      "0        Memory          8\n",
      "         Presentation    8\n",
      "1        Memory          8\n",
      "         Presentation    8\n",
      "2        Memory          8\n",
      "         Presentation    8\n",
      "3        Memory          8\n",
      "         Presentation    8\n",
      "4        Memory          8\n",
      "         Presentation    8\n",
      "5        Memory          8\n",
      "         Presentation    8\n",
      "7        Memory          8\n",
      "         Presentation    8\n",
      "8        Memory          8\n",
      "         Presentation    8\n",
      "10       Memory          8\n",
      "         Presentation    8\n",
      "12       Memory          8\n",
      "         Presentation    8\n",
      "13       Memory          8\n",
      "         Presentation    8\n",
      "14       Memory          8\n",
      "         Presentation    8\n",
      "15       Memory          8\n",
      "         Presentation    8\n",
      "16       Memory          8\n",
      "         Presentation    8\n",
      "17       Memory          8\n",
      "         Presentation    8\n",
      "18       Memory          8\n",
      "         Presentation    8\n",
      "19       Memory          8\n",
      "         Presentation    8\n",
      "20       Memory          8\n",
      "         Presentation    8\n",
      "21       Memory          8\n",
      "         Presentation    8\n",
      "22       Memory          8\n",
      "         Presentation    8\n",
      "23       Memory          8\n",
      "         Presentation    8\n",
      "24       Memory          8\n",
      "         Presentation    8\n",
      "25       Memory          8\n",
      "         Presentation    8\n",
      "26       Memory          8\n",
      "         Presentation    8\n",
      "27       Memory          8\n",
      "         Presentation    8\n",
      "28       Memory          8\n",
      "         Presentation    8\n",
      "29       Memory          8\n",
      "         Presentation    8\n",
      "33       Memory          8\n",
      "         Presentation    8\n",
      "34       Memory          8\n",
      "         Presentation    8\n",
      "327      Memory          8\n",
      "         Presentation    8\n",
      "Name: Run, dtype: int64\n",
      "\n",
      "../variable_attention_experiment/data\n",
      "group2\n",
      "\n",
      "We have loaded data from 23 unique subjects\n",
      "\n",
      "Below, we can see the number of unique runs loaded for each subject, for each trial type.\n",
      "\n",
      "The set of all numbers of runs from all participants contains 1 unique value: [8]\n",
      "\n",
      "Subject  Trial Type  \n",
      "0        Memory          8\n",
      "         Presentation    8\n",
      "5        Memory          8\n",
      "         Presentation    8\n",
      "6        Memory          8\n",
      "         Presentation    8\n",
      "8        Memory          8\n",
      "         Presentation    8\n",
      "9        Memory          8\n",
      "         Presentation    8\n",
      "10       Memory          8\n",
      "         Presentation    8\n",
      "11       Memory          8\n",
      "         Presentation    8\n",
      "12       Memory          8\n",
      "         Presentation    8\n",
      "14       Memory          8\n",
      "         Presentation    8\n",
      "15       Memory          8\n",
      "         Presentation    8\n",
      "16       Memory          8\n",
      "         Presentation    8\n",
      "17       Memory          8\n",
      "         Presentation    8\n",
      "18       Memory          8\n",
      "         Presentation    8\n",
      "19       Memory          8\n",
      "         Presentation    8\n",
      "20       Memory          8\n",
      "         Presentation    8\n",
      "21       Memory          8\n",
      "         Presentation    8\n",
      "25       Memory          8\n",
      "         Presentation    8\n",
      "26       Memory          8\n",
      "         Presentation    8\n",
      "27       Memory          8\n",
      "         Presentation    8\n",
      "28       Memory          8\n",
      "         Presentation    8\n",
      "29       Memory          8\n",
      "         Presentation    8\n",
      "30       Memory          8\n",
      "         Presentation    8\n",
      "56       Memory          8\n",
      "         Presentation    8\n",
      "Name: Run, dtype: int64\n"
=======
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../sustained_attention_experiment/data/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e11a77fbe3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# aggregate all the data from the participant into a dataframe, and append to a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msub_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_pd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'We have loaded data from {len(sub_list)} unique subjects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/data_add_only/attention-memory-task/data_analysis_code/analysis_helpers.py\u001b[0m in \u001b[0;36msum_pd\u001b[0;34m(subdir)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# list all files in the subject's directory that contain pres or mem run data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'pres'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'mem'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# read in the data from each of these files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../sustained_attention_experiment/data/.DS_Store'"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
     ]
    }
   ],
   "source": [
    "# for each experiment's data directory\n",
    "for data_dir in ['../sustained_attention_experiment/data', '../variable_attention_experiment/data']:\n",
    "    \n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "    for group in ['group1', 'group2']:\n",
    "        \n",
    "        sub_list = []\n",
    "\n",
    "        # for each participant directory in the data directory\n",
    "        for sub_dir in [f for f in os.listdir(data_dir+'/'+group) if f != '.DS_Store']:\n",
    "\n",
    "            # aggregate all the data from the participant into a dataframe, and append to a list\n",
    "            sub_list.append(sum_pd(data_dir + '/' + group + '/' + sub_dir))\n",
    "            \n",
    "        print()\n",
    "        print(data_dir)\n",
    "        print(group)\n",
    "        print()\n",
    "            \n",
    "        print(f'We have loaded data from {len(sub_list)} unique subjects')\n",
    "\n",
    "        ############################################\n",
    "\n",
    "        # Concatenate the list into single dataframe \n",
    "        concatenated = pd.concat(sub_list)\n",
    "\n",
    "        # obtain the number of unique runs for each participant for each trial type (Presentation and Memory)\n",
    "        unique_runs = concatenated.groupby(['Subject','Trial Type'])['Run'].nunique()\n",
    "\n",
    "        print()\n",
    "        print('Below, we can see the number of unique runs loaded for each subject, for each trial type.')\n",
    "        print()\n",
    "        print('The set of all numbers of runs from all participants contains '\n",
    "              + str(unique_runs.nunique()) + ' unique value: '+str(unique_runs.unique()))\n",
    "        print()\n",
    "        print(str(unique_runs))"
=======
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
    "    sub_list = []\n",
    "\n",
    "    # for each participant directory in the data directory\n",
    "    for sub_dir in os.listdir(data_dir):\n",
    "        \n",
    "        # aggregate all the data from the participant into a dataframe, and append to a list\n",
    "        sub_list.append(sum_pd(data_dir + '/' + sub_dir))\n",
    "\n",
    "    print(f'We have loaded data from {len(sub_list)} unique subjects')\n",
    "\n",
    "    ############################################\n",
    "\n",
    "    # Concatenate the list into single dataframe \n",
    "    concatenated = pd.concat(sub_list)\n",
    "    \n",
    "    # obtain the number of unique runs for each participant for each trial type (Presentation and Memory)\n",
    "    unique_runs = concatenated.groupby(['Subject','Trial Type'])['Run'].nunique()\n",
    "    \n",
    "    print()\n",
    "    print('Below, we can see the number of unique runs loaded for each subject, for each trial type.')\n",
    "    print()\n",
    "    print('The set of all numbers of runs from all participants contains '\n",
    "          + str(unique_runs.nunique()) + ' unique value: '+str(unique_runs.unique()))\n",
    "    print()\n",
    "    print(str(unique_runs))"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check B1: check attention level assignments"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": null,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
   "execution_count": null,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
   "execution_count": null,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in labeled data\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "data = pd.read_csv('../parsed_data/full_behavioral.csv')"
=======
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
    "exp1 = pd.read_csv('../parsed_data/behavioral_data_sustained.csv')\n",
    "exp2 = pd.read_csv('../parsed_data/behavioral_data_variable.csv')\n",
    "\n",
    "\n",
    "# label rows by trial number\n",
    "# see the check in issue #83, where we confirm that all rows are in the temporal order from the experiment \n",
    "# (early trials at the top, late trials at the bottom)\n",
    "for exp in [exp1, exp2]:\n",
    "\n",
    "    # Number all presentation and memory trials \n",
    "    exp.loc[exp['Trial Type']=='Memory','Trial'] = list(range(0,40))*30*8\n",
    "    exp.loc[exp['Trial Type']=='Presentation','Trial'] = list(range(0,10))*30*8"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "### Check B1a: Number of images at each attention level, in each memory run\n",
    "\n",
    "This cell outputs the unique counts for each type of non-novel image shown in memory run (Fully Attended, Side, Category, and None) and for novel images shown in memory run.\n",
    "\n",
    "All participants should see five of each non-novel image type, and 20 novel images."
=======
    "### Check B1a: Number of images at each attention level, in each memory run"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
    "### Check B1a: Number of images at each attention level, in each memory run"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
    "### Check B1a: Number of images at each attention level, in each memory run"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique number of each non-novel image type: [5]\n",
      "unique number of novel images: [20]\n"
     ]
    }
   ],
   "source": [
    "attn_grp = data.groupby(['UniqueID','Run','Trial Type','Attention Level'], as_index=False).count()\n",
    "print('unique number of each non-novel image type: '+str(attn_grp[attn_grp['Attention Level']!='Novel']['Subject'].unique()))\n",
    "print('unique number of novel images: '+str(attn_grp[attn_grp['Attention Level']=='Novel']['Subject'].unique()))"
=======
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each experiment\n",
    "for exp in [exp1, exp2]:\n",
    "      \n",
    "    # number of unique images at each attention level (prev-seen images and Novel images)\n",
    "    unique_seen  = exp[exp['Attention Level']!='Novel'].groupby(['Subject','Run', 'Attention Level'])['Trial'].nunique()\n",
    "    unique_novel = exp[exp['Attention Level']=='Novel'].groupby(['Subject','Run', 'Attention Level'])['Trial'].nunique()\n",
    "\n",
    "    for name,data in zip(['novel','previously seen'],[unique_novel, unique_seen]):\n",
    "\n",
    "        print('The set of the numbers of ' + name + ' images from each attention level, displayed to each participant, in each run, contains '+\n",
    "              str(data.nunique())+' unique value : '+str(data.unique()))\n",
    "        print()\n",
    "        print(data)\n",
    "        print()"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "### Check B1b: Novel images equal proportion faces and places\n",
    "\n",
    "\n",
    "This cell outputs the unique counts for novel images shown in each category (Faces and Places). All participants should see 10 of each image type."
=======
    "### Check B1b: Novel images equal proportion faces and places"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
    "### Check B1b: Novel images equal proportion faces and places"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
    "### Check B1b: Novel images equal proportion faces and places"
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique number of each non-novel image type: [10]\n",
      "unique number of novel images: [10]\n"
     ]
    }
   ],
   "source": [
    "attn_grp = data.groupby(['UniqueID','Run','Trial Type','Attention Level','Category'], as_index=False).count()\n",
    "print('unique number of each non-novel image type: '+str(attn_grp[(attn_grp['Attention Level']=='Novel') & (attn_grp['Category']=='Place')]['Subject'].unique()))\n",
    "print('unique number of novel images: '+str(attn_grp[(attn_grp['Attention Level']=='Novel') & (attn_grp['Category']=='Place')]['Subject'].unique()))"
=======
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novel Faces and Places\n",
    "for exp in [exp1, exp2]:\n",
    "    \n",
    "    # number of unique images at each attention level (prev-seen images and Novel images)\n",
    "    unique_novel = exp[exp['Attention Level']=='Novel'].groupby(['Subject','Run', 'Attention Level','Category'])['Trial'].nunique()\n",
    "\n",
    "    print('The set of the numbers of Novel face images and Novel place images displayed to each participant, in each run, contains '+\n",
    "    str(unique_novel.nunique())+' unique value(s) : '+str(unique_novel.unique()))\n",
    "    \n",
    "    print()\n",
    "    print(unique_novel)\n",
    "    print()"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "# Check B1c: Check category consistency, sustained exp\n",
=======
    "# Check B1c: \n",
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
    "# Check B1c: \n",
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
    "# Check B1c: \n",
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
    "###### Full  and  Category   images from each run are same image category\n",
    "###### Side  and   None       images from each run are same image category"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mismatches detected.\n"
     ]
    }
   ],
   "source": [
    "data_match = data[data['Experiment']=='/sustain']\n",
    "match_grp  = data_match.groupby(['UniqueID','Run','Attention Level','Category'],as_index=False).count()\n",
    "\n",
    "counts = 0\n",
    "\n",
    "for s in match_grp['UniqueID'].unique():\n",
    "    for r in match_grp['Run'].unique():\n",
    "        \n",
    "        d = match_grp[(match_grp['UniqueID']==s)&(match_grp['Run']==r)]\n",
    "        \n",
    "        if d[d['Attention Level']=='Full']['Category'].item() != d[d['Attention Level']=='Category']['Category'].item():\n",
    "            print('Full and Category Face/Place mismatch')\n",
    "            count += 1\n",
    "            \n",
    "        if d[d['Attention Level']=='Side']['Category'].item() != d[d['Attention Level']=='None']['Category'].item():\n",
    "            print('Side and None Face/Place mismatch')\n",
    "            count += 1\n",
    "            \n",
    "if counts ==  0:\n",
    "    print('No mismatches detected.')"
=======
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check B2: Randomly select runs from random participants to spot check manually"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 3,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
   "execution_count": 3,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
   "execution_count": 3,
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select two participants\n",
    "# randomly select a run from each participant's data\n",
    "# output randomly selected runs to html file for manual check"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one participant from each experiment and group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Attention Cuing\n",
    "\n",
    "See if participants in sustained attn experiment saw the same cue in back-to-back blocks.\n",
    "\n",
    "See if participants in variable attn experiment saw same cue in back-to-back trials.\n",
    "\n",
    "In both experiments, there are instances of repeated cues in the first test group but not the second (see output below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['combined_cue'] = data['Cued Category'] + data['Cued Side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sustained attn, group 1: 29 instances of repeated cues in back to back blocks\n",
      "/sustained attn, group 2: 0 instances of repeated cues in back to back blocks\n"
     ]
    }
   ],
   "source": [
    "for exp in ['/sustain']:\n",
    "    \n",
    "    for group in [1,2]:\n",
    "        \n",
    "        repeat_instances = 0\n",
    "        \n",
    "        for sub in data[(data['Experiment']==exp)&(data['Group']==group)]['UniqueID'].unique():\n",
    "\n",
    "            d = data[data['UniqueID']==sub].groupby(['Run','combined_cue'],as_index=False).count()\n",
    "            cue_list = list(d['combined_cue'])\n",
    "\n",
    "            for idx,x in enumerate(cue_list):\n",
    "                if idx>0:\n",
    "                    if cue_list[idx]==cue_list[idx-1]:\n",
    "                        repeat_instances += 1\n",
    "                        \n",
    "        print(exp+'ed attn, group '+str(group)+': '+str(repeat_instances)+' instances of repeated cues in back to back blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/variable attn, group 1: 360 instances of repeated cues in back to back blocks\n",
      "/variable attn, group 2: 0 instances of repeated cues in back to back blocks\n"
     ]
    }
   ],
   "source": [
    "for exp in ['/variabl']:\n",
    "    \n",
    "    for group in [1,2]:\n",
    "        \n",
    "        repeat_instances = 0\n",
    "        \n",
    "        for sub in data[(data['Experiment']==exp)&(data['Group']==group)]['UniqueID'].unique():\n",
    "            \n",
    "            d = data[data['UniqueID']==sub].groupby(['Run','Trial','combined_cue'],as_index=False).count()\n",
    "            \n",
    "            for r in d['Run'].unique():\n",
    "                cue_list = list(d[d['Run']==r]['combined_cue'])\n",
    "\n",
    "                for idx,x in enumerate(cue_list):\n",
    "                    if idx>0:\n",
    "                        if cue_list[idx]==cue_list[idx-1]:\n",
    "                            repeat_instances += 1\n",
    "                        \n",
    "        print(exp+'e attn, group '+str(group)+': '+str(repeat_instances)+' instances of repeated cues in back to back trials')"
   ]
=======
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-56f2cc947637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'exp2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Run'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp1' is not defined"
     ]
    }
   ],
   "source": [
    "for exp_name,exp,seed in zip(['exp1','exp2'],[exp1,exp2],[1,2]):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    sub = random.sample(list(exp['Subject'].unique()), 2)\n",
    "    run = random.sample(list(exp['Run'].unique()), 2)    \n",
    "\n",
    "    for s,r in zip(sub,run):\n",
    "        exp[(exp['Subject']==s) & (exp['Run']==r)].to_csv(exp_name+'_'+str(s)+'_'+str(r)+'_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
=======
>>>>>>> 6d729aa13dc8cd666332aa6ba2aaf15520192cd3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
