{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates timecourse analyses and figures for experiments 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import seaborn as sb; import warnings; import scipy; import re; \n",
    "import os; from analysis_helpers import *; import itertools; from scipy import stats\n",
    "import random; import pandas as pd; import numpy as np; from sklearn import datasets, linear_model; \n",
    "from sklearn.linear_model import LinearRegression; import statsmodels.api as sm\n",
    "from scipy import stats; from itertools import groupby; from operator import itemgetter; import pingouin\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Behavioral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../parsed_data/full_behavioral.csv')\n",
    "\n",
    "# Load restricted behavioral data !\n",
    "data = pd.read_csv('../parsed_data/behav_restricted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.205673143161672,\n",
       " 28.783839299197314,\n",
       " 30.34221782326572,\n",
       " 30.112267103539434,\n",
       " 30.00696444758717,\n",
       " 29.894583386612858,\n",
       " 30.117804290265347,\n",
       " 29.892066429830408,\n",
       " 29.28121348073937,\n",
       " 30.24573398284545,\n",
       " 30.117811449136383,\n",
       " 29.80977849127048,\n",
       " 29.72736647383527,\n",
       " 29.54896522955172,\n",
       " 30.438092125108493,\n",
       " 30.287094350328932,\n",
       " 30.21828389404297,\n",
       " 30.57604130388957,\n",
       " 30.496903515922746,\n",
       " 30.043577641420704,\n",
       " 30.697622203815733,\n",
       " 30.317913996403394,\n",
       " 30.587369468361736,\n",
       " 30.452241534909163,\n",
       " 30.328912077994012,\n",
       " 30.09055121682041,\n",
       " 30.50938326201648,\n",
       " 30.23632799286265,\n",
       " 28.740540538736976,\n",
       " 27.77904012939453,\n",
       " 27.533148906249995,\n",
       " 27.62901268676757,\n",
       " 27.4224948010254,\n",
       " 27.465172744140624,\n",
       " 27.592476165574602,\n",
       " 27.506669721679692,\n",
       " 27.58658878090716,\n",
       " 27.957004543457032,\n",
       " 29.182110311306435,\n",
       " 27.887478400065106,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 27.30086921316964,\n",
       " 27.356390697102853,\n",
       " 27.486426649169907,\n",
       " 27.412163673095712,\n",
       " 27.669897578179878,\n",
       " 27.57364295205391,\n",
       " 27.862876347131227,\n",
       " 28.17806410986329,\n",
       " 27.930240357652888,\n",
       " 27.802176179172953,\n",
       " 28.43062055297852,\n",
       " 28.33649110003532,\n",
       " 28.44326196637834,\n",
       " 28.428603712158203,\n",
       " 28.26172993218925,\n",
       " 28.472779841657356,\n",
       " 28.37596664903429,\n",
       " 28.389695951450896,\n",
       " 27.424600276925222,\n",
       " 27.366563007033314,\n",
       " 27.45092255233227,\n",
       " 27.585253103027345,\n",
       " 27.155312288682733,\n",
       " 27.29205448833265,\n",
       " 27.461998538762867,\n",
       " 27.20056630337801,\n",
       " 27.340711320657157,\n",
       " 28.267499783935552,\n",
       " 28.155089710864,\n",
       " 28.679979116699208,\n",
       " 28.39700281529017,\n",
       " 28.013496907808108,\n",
       " 27.886940811767587,\n",
       " 28.174691457207857,\n",
       " 27.787114998779288,\n",
       " 27.90242896782768,\n",
       " 28.0973961010742,\n",
       " 29.742847490115288,\n",
       " 29.98879651563691,\n",
       " 30.123090452731976,\n",
       " 29.66696553966987,\n",
       " 29.3721562241152,\n",
       " 29.264284846691442,\n",
       " 29.207653049875283,\n",
       " 27.55060573521205,\n",
       " 27.65243223754881,\n",
       " 27.84650905907165,\n",
       " 28.10761889038085,\n",
       " 28.32912967464193,\n",
       " 27.828284868932137,\n",
       " 27.479964065290165,\n",
       " 27.560794188794784,\n",
       " 28.316542255911315,\n",
       " 28.011971482694893,\n",
       " 28.087553594928607,\n",
       " 27.98272205423991,\n",
       " 28.3156924783161,\n",
       " 28.104403120117194,\n",
       " 27.97743711142264,\n",
       " 28.164239301757817,\n",
       " 28.118355093994154,\n",
       " 27.816124962158217,\n",
       " 27.989515155552464,\n",
       " 28.031592416992183,\n",
       " 28.43508251116072,\n",
       " 27.900154091099328,\n",
       " 27.738783811848954,\n",
       " 27.79809292271204,\n",
       " 26.46213339843749,\n",
       " 29.74786448906957,\n",
       " 29.46885580197218,\n",
       " 29.751498437382327,\n",
       " 29.997204480657,\n",
       " 29.60255762373621,\n",
       " 30.007811041376023,\n",
       " 30.240288001724053,\n",
       " 29.768971199834922,\n",
       " 29.765398367235136,\n",
       " 29.953780292667336,\n",
       " 29.74252511658469,\n",
       " 29.900003658914446,\n",
       " 30.559230181252328,\n",
       " 30.08313909622397,\n",
       " 30.092107447858538,\n",
       " 29.240719347270442,\n",
       " 29.31773357171779,\n",
       " 29.83369250899152,\n",
       " 29.682280814774696,\n",
       " 29.79498432484569,\n",
       " 29.997394848751906,\n",
       " 33.32365210824362,\n",
       " 29.82987963346353,\n",
       " 29.30745054713893,\n",
       " 29.84456215220256,\n",
       " 29.968858956231017,\n",
       " 29.409972222222205,\n",
       " 29.61612178873697,\n",
       " 30.32893692492676,\n",
       " 29.946095782771913,\n",
       " 30.3831301596743,\n",
       " 29.589458828546967,\n",
       " 30.062231260864266,\n",
       " 29.51432148040772,\n",
       " 29.56932074560546,\n",
       " 30.06930424237061,\n",
       " 29.611616948242194,\n",
       " 29.74010080773925,\n",
       " 30.02297286156345,\n",
       " 30.554708721969032,\n",
       " 31.22191477616473,\n",
       " 29.67385245534873,\n",
       " 29.694475921898817,\n",
       " 28.99186384012613,\n",
       " 28.949962236387677,\n",
       " 28.85430376190929,\n",
       " 29.699390120081,\n",
       " 29.460861305140046,\n",
       " 29.92855623058784,\n",
       " 29.90851901626398,\n",
       " 30.926805661085176,\n",
       " 30.947204769435967,\n",
       " 29.464330101538955,\n",
       " 29.584039562571448,\n",
       " 30.11975368530273,\n",
       " 30.349392125154814,\n",
       " 30.111394652248478,\n",
       " 29.98944959889482,\n",
       " 30.110739859768,\n",
       " 30.22818205530678,\n",
       " 30.408638942394727,\n",
       " 30.44603025122666,\n",
       " 30.053819795745483,\n",
       " 30.346659376235408,\n",
       " 30.123615789407857,\n",
       " 30.33934846632052,\n",
       " 30.369861365043825,\n",
       " 30.36723605260339,\n",
       " 30.71773628150009,\n",
       " 29.684039213093094,\n",
       " 29.611245896362313,\n",
       " 30.187526536602554,\n",
       " 29.670970633177234,\n",
       " 29.841323155070967,\n",
       " 30.067237029820884,\n",
       " 29.83226119533632,\n",
       " 29.850394764791346,\n",
       " 29.99404659209828,\n",
       " 29.900318485137202,\n",
       " 29.398068272769326,\n",
       " 29.427250202508226,\n",
       " 29.216888355165672,\n",
       " 28.706678654841923,\n",
       " 28.16664446437193,\n",
       " 28.24152914127212,\n",
       " 28.39200764171253,\n",
       " 27.61632778923807,\n",
       " 27.92089574802442,\n",
       " 27.84131583198051,\n",
       " 28.05851466745173,\n",
       " 27.630753220526515,\n",
       " 27.781361798660107,\n",
       " 28.25392152758221,\n",
       " 28.30817394764034,\n",
       " 28.28548527794054,\n",
       " 28.311723510639407,\n",
       " 28.233541891561977,\n",
       " 27.89836818786621,\n",
       " 27.845163992753463,\n",
       " 28.259085609989885,\n",
       " 28.09650876150173,\n",
       " 28.59055990486393,\n",
       " 28.381388374307328,\n",
       " 28.483489864501962,\n",
       " 28.1283734796007,\n",
       " 28.467226026611318,\n",
       " 28.502276832275392,\n",
       " 28.46044333056641,\n",
       " 28.40241474243164,\n",
       " 28.076927483881477,\n",
       " 30.127914199278287,\n",
       " 29.85805092435861,\n",
       " 29.724590974452628,\n",
       " 29.44523826271883,\n",
       " 29.540315105362858,\n",
       " 29.76645414288329,\n",
       " 29.271979863464345,\n",
       " 28.936958756014185,\n",
       " 30.17104537091289,\n",
       " 30.249811111755378,\n",
       " 29.83467159084413,\n",
       " 29.64812862051506,\n",
       " 30.61677622154707,\n",
       " 30.869310567491322,\n",
       " 30.621202895206398,\n",
       " 30.663935100752678,\n",
       " 29.998378476441943,\n",
       " 30.24566483698465,\n",
       " 29.458277704406754,\n",
       " 30.48200746476139,\n",
       " 30.559032375488282,\n",
       " 27.357632458767362,\n",
       " 28.216262406461787,\n",
       " 29.02600045606661,\n",
       " 28.97869667123189,\n",
       " 29.080388434284487,\n",
       " 27.81972373761432,\n",
       " 27.73720139115768,\n",
       " 27.47114507790304,\n",
       " 27.68018810464582,\n",
       " 27.57488502999443,\n",
       " 27.38555558430989,\n",
       " 28.19091313988375,\n",
       " 27.80746191541883,\n",
       " 27.74127728384367,\n",
       " 27.924751689453128,\n",
       " 27.756529071044927,\n",
       " 28.2795661273262,\n",
       " 27.989928725585926,\n",
       " 28.28943564600133,\n",
       " 28.47445857386577,\n",
       " 27.728404907226558,\n",
       " 27.69334120231466,\n",
       " 27.78013242088745,\n",
       " 27.72984384155273,\n",
       " 27.675884346175657,\n",
       " 27.71780806640626,\n",
       " 27.729341260463165,\n",
       " 27.19179183088434,\n",
       " 26.193841111219612,\n",
       " 26.42610185128348,\n",
       " 26.473537440723707,\n",
       " 28.532935340851818,\n",
       " 28.191047986886172,\n",
       " 27.606319228515616,\n",
       " 27.614506155831467,\n",
       " 27.710858636474608,\n",
       " 28.17335774169921,\n",
       " 27.844004346400677,\n",
       " 28.48305603177156,\n",
       " 28.03198604248048,\n",
       " 28.11987011555989,\n",
       " 28.03552938597195,\n",
       " 28.018441827582453,\n",
       " 28.086565412597647,\n",
       " 30.139225501708978,\n",
       " 28.314403740969425,\n",
       " 27.485507569056917,\n",
       " 27.71335022481939,\n",
       " 27.548662682717065,\n",
       " 28.149691709642738,\n",
       " 28.33115904227121,\n",
       " 28.335337995605467,\n",
       " 28.788241221923823,\n",
       " 28.2743005266462,\n",
       " 28.34949084141709,\n",
       " 28.29898135881698,\n",
       " 28.15157607101779,\n",
       " 28.7451955607884,\n",
       " 28.862555218460642,\n",
       " 27.7159644583855,\n",
       " 28.54332411010744,\n",
       " 28.13168823486325,\n",
       " 29.04086764659411,\n",
       " 28.47610562833177,\n",
       " 27.6048002766927,\n",
       " 28.318983692524004,\n",
       " 28.48916890237948,\n",
       " 28.321483130418734,\n",
       " 28.53026429663969,\n",
       " 29.4612337217882,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 27.73924346958707,\n",
       " 28.001294331054684,\n",
       " 27.3338300342882,\n",
       " 27.395375578530974,\n",
       " 27.9335320690918,\n",
       " 27.570733629286032,\n",
       " 27.78813865356445,\n",
       " 27.82864692192925,\n",
       " 28.563220489501948,\n",
       " 28.45891281180244,\n",
       " 28.772752368164053,\n",
       " 28.41385748881679,\n",
       " 28.45074126604352,\n",
       " 28.056743124131952,\n",
       " 28.27391870314695,\n",
       " 27.7329978225495,\n",
       " 27.62861623014322,\n",
       " 27.130907690100514,\n",
       " 27.213556309417363,\n",
       " 27.304155703176942,\n",
       " 28.34358044311524,\n",
       " 28.094741374860483,\n",
       " 27.955160708007806,\n",
       " 28.3044138734654,\n",
       " 27.923194905831476,\n",
       " 27.118009654079852,\n",
       " 27.443090743668794,\n",
       " 27.801818450996297,\n",
       " 27.63539713797433,\n",
       " 28.253172092285162,\n",
       " 27.52921669982911,\n",
       " 27.3239405111202,\n",
       " 27.83013136991768,\n",
       " 27.438177801339283,\n",
       " 27.74406387695312,\n",
       " 27.437564622558583,\n",
       " 27.855297237548836,\n",
       " 27.56381117583549,\n",
       " 27.95305351353237,\n",
       " 27.692536864356562,\n",
       " 27.772525493164057,\n",
       " 27.540479816592782,\n",
       " 26.75795840266927,\n",
       " 27.140206367885042,\n",
       " 27.56913357910157,\n",
       " 27.2929692765562,\n",
       " 27.403706247059212,\n",
       " 28.578533779622386,\n",
       " 28.313879279568127,\n",
       " 28.22810161900113,\n",
       " 28.492345114746104,\n",
       " 29.574464818264108,\n",
       " 29.123611577030797,\n",
       " 29.849284197432358,\n",
       " 29.696404192013613,\n",
       " 31.349595971860538,\n",
       " 30.20339842255741,\n",
       " 29.35935006091607,\n",
       " 29.332035794171578,\n",
       " 29.160878874129327,\n",
       " 29.778152785909267,\n",
       " 29.411420624647022,\n",
       " 29.29429824314024,\n",
       " 29.08427330131717,\n",
       " 29.367552175734183,\n",
       " 28.29614900860363,\n",
       " 28.70256510766005,\n",
       " 29.352240798935316,\n",
       " 29.42593124118713,\n",
       " 29.44426646329553,\n",
       " 29.407737866746857,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 27.275104001438585,\n",
       " 27.77215788623045,\n",
       " 29.840598836401966,\n",
       " 29.17595516268102,\n",
       " 29.0936049567871,\n",
       " 29.24030313684976,\n",
       " 29.619333601907865,\n",
       " 29.470509015842012,\n",
       " 30.33498514160157,\n",
       " 29.079405011718755,\n",
       " 27.553870020751948,\n",
       " 27.792658659517258,\n",
       " 28.12398032116837,\n",
       " 28.37810695176867,\n",
       " 28.42049491838726,\n",
       " 27.346265608452693,\n",
       " 27.36910724886068,\n",
       " 27.244858302495444,\n",
       " 28.394920316134982,\n",
       " 27.152524394531245,\n",
       " 28.035929698486317,\n",
       " 28.106619493869356,\n",
       " 28.650719614257806,\n",
       " 28.32078281110491,\n",
       " 28.49565624197047,\n",
       " 28.199040735992106,\n",
       " 28.251990125558038,\n",
       " 26.70408253696986,\n",
       " 26.637119203524023,\n",
       " 26.609385607638888,\n",
       " 27.280241713867184,\n",
       " 26.922869161966748,\n",
       " 26.697923820800785,\n",
       " 27.83366508378699,\n",
       " 27.85972488647461,\n",
       " 28.12164087890625,\n",
       " 28.125187060546885,\n",
       " 27.56741334838869,\n",
       " 27.53339330466651,\n",
       " 28.036144831891736,\n",
       " 27.867350583713108,\n",
       " 27.88990565917968,\n",
       " 28.53841930126403,\n",
       " 27.580174396639748,\n",
       " 28.36827331891742,\n",
       " 27.938258010253914,\n",
       " 28.111302465820323,\n",
       " 27.825923608127173,\n",
       " 27.931727703683034,\n",
       " 27.856055725694443,\n",
       " 27.74247058998025,\n",
       " 28.085260524902353,\n",
       " 27.975486143120648,\n",
       " 27.697186310686373,\n",
       " 28.243824927860388,\n",
       " 28.27671326486545,\n",
       " 28.352183840883328,\n",
       " 28.09347654926914,\n",
       " 28.028701400146485,\n",
       " 28.1591978641183,\n",
       " 28.48699118164061,\n",
       " 28.25712480817522,\n",
       " 28.05798620117188,\n",
       " 28.40048782588836,\n",
       " 28.54435644531249,\n",
       " 27.973342744140634,\n",
       " 28.02411995632596,\n",
       " 28.21352635852444,\n",
       " 28.37134902709961,\n",
       " 28.127198119419646,\n",
       " 28.50365562255859,\n",
       " 28.595872642822265,\n",
       " 28.83182664691033,\n",
       " 28.63772917425605,\n",
       " 28.276589398207086,\n",
       " 28.290036870289523,\n",
       " 29.0916705234585,\n",
       " 28.78154929260253,\n",
       " 28.97118412570529,\n",
       " 28.8575517766462,\n",
       " 29.19785724323679,\n",
       " 28.81843119755497,\n",
       " 28.683111823586863,\n",
       " 28.479393787780765,\n",
       " 28.75066400948661,\n",
       " 28.98885108537948,\n",
       " 28.87409313406809,\n",
       " 28.81306156564296,\n",
       " 28.991796817503523,\n",
       " 28.880380544084826,\n",
       " 28.93032978655133,\n",
       " 28.73797936633695,\n",
       " 27.803353861111113,\n",
       " 27.84290886740945,\n",
       " 28.05721051199777,\n",
       " 27.809021218587237,\n",
       " 27.918180164620548,\n",
       " 27.97934067626954,\n",
       " 28.085953027510207,\n",
       " 28.086465197726454,\n",
       " 28.343500275800142,\n",
       " 28.239976770670577,\n",
       " 28.600659394531245,\n",
       " 28.152003717540392,\n",
       " 28.752879171316966,\n",
       " 29.26663400810773,\n",
       " 29.532908085493606,\n",
       " 27.82448796984725,\n",
       " 27.926608995243182,\n",
       " 28.07281900756836,\n",
       " 28.235471271972656,\n",
       " 28.07633444676086,\n",
       " 28.017520067138662,\n",
       " 28.18160962500001,\n",
       " 28.166100495256707,\n",
       " 28.879647868652352,\n",
       " 28.886857463270378,\n",
       " 28.70906224864613,\n",
       " 28.56198326764395,\n",
       " 28.0055747376302,\n",
       " 28.234048428955077,\n",
       " 28.772928467887702,\n",
       " 27.696261348170218,\n",
       " 27.396399732926607,\n",
       " 27.557019733318963,\n",
       " 28.017336280273433,\n",
       " 28.271314500590485,\n",
       " 28.126213789617356,\n",
       " 28.390420368065186,\n",
       " 27.514985175256214,\n",
       " 27.57223751116072,\n",
       " 27.721447443450216,\n",
       " 28.032303361816407,\n",
       " 28.103518032453657,\n",
       " 28.132084946171407,\n",
       " 27.943893042643232,\n",
       " 27.862425860770088,\n",
       " 28.112811016401825,\n",
       " 27.24744118861608,\n",
       " 27.25898221795195,\n",
       " 27.917268778502002,\n",
       " 27.757067985473622,\n",
       " 27.88767400809153,\n",
       " 28.31599843889508,\n",
       " 28.50770932686943,\n",
       " 28.199252243652353,\n",
       " 28.268079873744426,\n",
       " 28.041139576305042,\n",
       " 28.31588431053647,\n",
       " 28.421566224365236,\n",
       " 28.34253398297991,\n",
       " 28.28378813895088,\n",
       " 30.757280890279645,\n",
       " 30.60151142631718,\n",
       " 30.71030118116425,\n",
       " 30.270949100550197,\n",
       " 28.735565922256104,\n",
       " 28.47621036031584,\n",
       " 28.044333981539808,\n",
       " 27.824456234879023,\n",
       " 28.36702906906291,\n",
       " 28.157066901959357,\n",
       " 27.718818359375,\n",
       " 28.58249102172851,\n",
       " 28.20593789496528,\n",
       " 28.22782331439567,\n",
       " 28.261959970269107,\n",
       " 28.008287178955086,\n",
       " 27.810612508505546,\n",
       " 28.316603193576388,\n",
       " 28.457422407281427,\n",
       " 27.613066136474615,\n",
       " 27.85363582101005,\n",
       " 28.956984887695306,\n",
       " 28.791537830295148,\n",
       " 29.752727643694183,\n",
       " 29.739835889892568,\n",
       " 29.53533472726006,\n",
       " 29.602934961635032,\n",
       " 29.289399417805985,\n",
       " 27.5051833511513,\n",
       " 28.56236882856391,\n",
       " 27.703414851074214,\n",
       " 27.640768251113073,\n",
       " 28.57237120339627,\n",
       " 28.28253104980468,\n",
       " 28.33312931570871,\n",
       " 27.808414285016728,\n",
       " 28.419671997767853,\n",
       " 28.63378787597656,\n",
       " 28.466787689208974,\n",
       " 29.012981574490013,\n",
       " 30.865379050947986,\n",
       " 31.095775490451388,\n",
       " 30.82786584526911,\n",
       " 30.09323660855516,\n",
       " 30.51163017728828,\n",
       " 29.50904874023437,\n",
       " 29.71344254150392,\n",
       " 29.23202946150415,\n",
       " 29.60411370014709,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 30.30462309100116,\n",
       " 30.234422587116537,\n",
       " 30.56236418035061,\n",
       " 29.73359466169945,\n",
       " 29.553613525149512,\n",
       " 30.248926564941396,\n",
       " 30.03432851324313,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 29.464730931604908,\n",
       " 29.605010210020488,\n",
       " 29.65815840142823,\n",
       " 29.309173851514288,\n",
       " 29.238578780547343,\n",
       " 32.407720527701024,\n",
       " 29.76417858057735,\n",
       " 29.91075480957027,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 29.593511427770547,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 29.269491067828888,\n",
       " 30.483341433437012,\n",
       " 30.262277644977328,\n",
       " 30.44081637463081,\n",
       " 30.47737956513195,\n",
       " 30.447596379811355,\n",
       " 30.666280973108787,\n",
       " 29.821371097441865,\n",
       " 29.916842518876233,\n",
       " 29.803608656563426,\n",
       " 28.94476130047605,\n",
       " 29.129111388820238,\n",
       " 28.58129704228155,\n",
       " 29.886267589617443,\n",
       " 29.286418869569346,\n",
       " 29.464827749083728,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 30.85145656077316,\n",
       " 30.98980514767529,\n",
       " 28.95007817166484,\n",
       " 29.239591087239575,\n",
       " 29.07601814386815,\n",
       " 28.97330348650677,\n",
       " 29.12574730092641,\n",
       " 29.436553350423182,\n",
       " 29.432663172200513,\n",
       " 29.662567710020493,\n",
       " 29.439543469777302,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 30.450389952859766,\n",
       " 30.36768628255209,\n",
       " 30.518318883104197,\n",
       " 29.888512671712235,\n",
       " 29.99857414110137,\n",
       " 30.04322204179929,\n",
       " 29.571535392795138,\n",
       " 29.776663336806887,\n",
       " 30.913335305577537,\n",
       " 30.65241582120029,\n",
       " 30.367050600585927,\n",
       " 29.625140546504145,\n",
       " 29.297327840129572,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 30.112052170560883,\n",
       " 30.48144304150794,\n",
       " 30.43354661151837,\n",
       " 29.76534078780015,\n",
       " 30.06414618393132,\n",
       " 29.685485722475395,\n",
       " 30.083881599359287,\n",
       " 30.193453056461987,\n",
       " 30.13717987697695,\n",
       " 30.157457622612807,\n",
       " 30.077540597310854,\n",
       " 29.955368946457845,\n",
       " 30.14208322084439,\n",
       " 30.268020680700218,\n",
       " 30.09378200309848,\n",
       " 30.16906845060024,\n",
       " 29.964476934211593,\n",
       " 29.998834174387856,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 29.79664693196616,\n",
       " 29.60665864637587,\n",
       " 29.85647458110289,\n",
       " 29.860403847477574,\n",
       " 29.972564276258673,\n",
       " 30.033077921386706,\n",
       " 30.131205841451496,\n",
       " 30.007065626288103,\n",
       " 30.102227714904032,\n",
       " 30.167733512171306,\n",
       " 30.36651945071373,\n",
       " 29.81384884455983,\n",
       " 30.188377576557667,\n",
       " 30.158601011397185,\n",
       " 30.02862598319349,\n",
       " 29.691290455066056,\n",
       " 29.363662233588986,\n",
       " 29.537567220654893,\n",
       " 29.55872562035537,\n",
       " 29.36932559395495,\n",
       " 29.329389258884344,\n",
       " 29.455375042739664,\n",
       " 29.93401114185473,\n",
       " 30.191202295219608,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 30.312744613007325,\n",
       " 30.04542483446661,\n",
       " 30.06519569757909,\n",
       " 30.37321984494093,\n",
       " 30.374220546392745,\n",
       " 30.759424895230516,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 29.686673481147576,\n",
       " 29.224417479932825,\n",
       " 29.477946473632823,\n",
       " 29.73365809919085,\n",
       " 29.49257896261161,\n",
       " nan,\n",
       " 29.51497886724779,\n",
       " 29.33015625470418,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 31.07941613320456,\n",
       " 31.219366562347428,\n",
       " 30.62368134265436,\n",
       " nan,\n",
       " 30.16425642638407,\n",
       " nan,\n",
       " 30.609097749023434,\n",
       " 30.669348621841234,\n",
       " 30.64499973578559,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 30.221398204375475,\n",
       " 30.342762335491425,\n",
       " 30.38845808545525,\n",
       " 30.657786063537593,\n",
       " 31.16795285903741,\n",
       " 30.918800071011763,\n",
       " 30.158133963035308,\n",
       " 30.248799748296953,\n",
       " 30.64473562704958,\n",
       " 30.552950622588764,\n",
       " 29.943564394897464,\n",
       " 30.3940379798852,\n",
       " 30.700696418635665,\n",
       " 30.93673987626237,\n",
       " 30.828330726109947,\n",
       " 31.57323252977324,\n",
       " 30.883296266536473,\n",
       " 31.07216805054211,\n",
       " 30.619914465391563,\n",
       " 31.314274078724942,\n",
       " 31.661829814155396,\n",
       " 31.03977291212152,\n",
       " 29.914011966085507,\n",
       " 29.859785394000703,\n",
       " 30.773595874803917,\n",
       " 30.611311833617172,\n",
       " 30.092438063994994,\n",
       " 30.019867083829546,\n",
       " 30.993116695169547,\n",
       " 30.85667873422017,\n",
       " 30.84464369140625,\n",
       " 31.00252829005112,\n",
       " 30.585359896270013,\n",
       " 30.836471449833628,\n",
       " 30.938628142963925,\n",
       " 29.639727816026465,\n",
       " 29.74239316134982,\n",
       " 29.45863767510137,\n",
       " 29.76027903201221,\n",
       " 29.879932061873063,\n",
       " 29.84189238311389,\n",
       " 29.980026443021785,\n",
       " 29.67678149801113,\n",
       " 30.360190815251013,\n",
       " 31.18333981290493,\n",
       " 31.304475915135512,\n",
       " 30.977813656744303,\n",
       " 30.53851710300351,\n",
       " 30.680758270640425,\n",
       " 30.84024144949776,\n",
       " 30.223894328077346,\n",
       " 30.566234896942138,\n",
       " 30.91764770001668,\n",
       " 30.18725383086412,\n",
       " 30.514215155285452,\n",
       " 30.530243053991203,\n",
       " 30.59570479619833,\n",
       " 30.74324281725261,\n",
       " 30.972431861780674,\n",
       " 29.43142197252941,\n",
       " 29.218588313802083,\n",
       " 29.990318446662798,\n",
       " 29.28825733362268,\n",
       " 30.03653317888958,\n",
       " 29.76327683913244,\n",
       " 29.73230580655725,\n",
       " 30.501554500204943,\n",
       " 30.452652153320305,\n",
       " 29.89386097240307,\n",
       " 29.942066798125488,\n",
       " 29.976043994020067,\n",
       " 30.03718400384598,\n",
       " 28.9888452100815,\n",
       " 29.39881249710648,\n",
       " 28.998544685872393,\n",
       " 29.251904397312607,\n",
       " 29.78147465588081,\n",
       " 29.933197186595763,\n",
       " 30.175363646978678,\n",
       " 30.070874611518665,\n",
       " 29.848257150521626,\n",
       " 30.116933405761714,\n",
       " 30.07165193389148,\n",
       " 29.873100742428626,\n",
       " 30.583271404344522,\n",
       " 30.289189735785605,\n",
       " 30.115776152404038,\n",
       " 30.311933853968164,\n",
       " 30.213253082305158,\n",
       " 29.822728485243047,\n",
       " 29.632828428156344,\n",
       " 29.71082876983265,\n",
       " 29.78243071664205,\n",
       " 29.888257035656448,\n",
       " 29.964586725260414,\n",
       " 29.975928801299673,\n",
       " 30.154943123779287,\n",
       " 29.85857978652581,\n",
       " 29.82895510365161,\n",
       " 30.092524544150265,\n",
       " 29.83990887297453,\n",
       " 29.717387328920733,\n",
       " 30.21536572952835,\n",
       " 29.96326275698061,\n",
       " 29.69448405653213,\n",
       " 30.198121655452088,\n",
       " 30.48597924940321,\n",
       " 30.185356250482254,\n",
       " 30.193557265625,\n",
       " 29.92823876241393,\n",
       " 28.94370361442659,\n",
       " 29.04834620867475,\n",
       " 29.006839109720374,\n",
       " 29.0288392538339,\n",
       " 29.095900679485048,\n",
       " 28.93134367525077,\n",
       " 29.345407540569536,\n",
       " 29.580179042017555,\n",
       " 29.900055676781932,\n",
       " 29.833449814453136,\n",
       " 29.77573572747952,\n",
       " 29.617397145724837,\n",
       " nan,\n",
       " 30.322846846125078,\n",
       " 30.503574255490182,\n",
       " 30.395503674429587,\n",
       " 30.177249027241906,\n",
       " 30.314226722620486,\n",
       " 30.24795945738971,\n",
       " 30.49006925787277,\n",
       " 30.4690276339458,\n",
       " 29.28681651439525,\n",
       " 29.633128790610705,\n",
       " 28.959220750325517,\n",
       " 29.337715665372528,\n",
       " 29.414665509982644,\n",
       " 29.23267460202065,\n",
       " 29.5794137926191,\n",
       " 29.406499515878178,\n",
       " 29.55601690923996,\n",
       " 29.475416836751318,\n",
       " nan,\n",
       " nan,\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data[data['Trial Type']=='Presentation']['av_x_coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Attention Button</th>\n",
       "      <th>Attention Level</th>\n",
       "      <th>Attention Probe</th>\n",
       "      <th>Attention Reaction Time (s)</th>\n",
       "      <th>Behavior_Image_Start</th>\n",
       "      <th>Category</th>\n",
       "      <th>Cue Validity</th>\n",
       "      <th>...</th>\n",
       "      <th>righteye</th>\n",
       "      <th>state</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>xRaw_lefteye</th>\n",
       "      <th>xRaw_righteye</th>\n",
       "      <th>yRaw_lefteye</th>\n",
       "      <th>yRaw_righteye</th>\n",
       "      <th>gaze_from_center</th>\n",
       "      <th>gaze_towards_cued_side</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th>Run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">0</td>\n",
       "      <td>0</td>\n",
       "      <td>2709</td>\n",
       "      <td>2709</td>\n",
       "      <td>2709</td>\n",
       "      <td>14</td>\n",
       "      <td>160</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2535</td>\n",
       "      <td>160</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2539</td>\n",
       "      <td>2539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3534</td>\n",
       "      <td>3534</td>\n",
       "      <td>3534</td>\n",
       "      <td>7</td>\n",
       "      <td>160</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3367</td>\n",
       "      <td>160</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3374</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3194</td>\n",
       "      <td>3194</td>\n",
       "      <td>3194</td>\n",
       "      <td>9</td>\n",
       "      <td>160</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3025</td>\n",
       "      <td>160</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>3025</td>\n",
       "      <td>3025</td>\n",
       "      <td>3025</td>\n",
       "      <td>3025</td>\n",
       "      <td>3025</td>\n",
       "      <td>3025</td>\n",
       "      <td>3025</td>\n",
       "      <td>3025</td>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4332</td>\n",
       "      <td>4332</td>\n",
       "      <td>4332</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4167</td>\n",
       "      <td>160</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4167</td>\n",
       "      <td>4167</td>\n",
       "      <td>4167</td>\n",
       "      <td>4167</td>\n",
       "      <td>4167</td>\n",
       "      <td>4167</td>\n",
       "      <td>4167</td>\n",
       "      <td>4167</td>\n",
       "      <td>4172</td>\n",
       "      <td>4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4221</td>\n",
       "      <td>4221</td>\n",
       "      <td>4221</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4051</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4051</td>\n",
       "      <td>4051</td>\n",
       "      <td>4051</td>\n",
       "      <td>4051</td>\n",
       "      <td>4051</td>\n",
       "      <td>4051</td>\n",
       "      <td>4051</td>\n",
       "      <td>4051</td>\n",
       "      <td>4060</td>\n",
       "      <td>4060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">327</td>\n",
       "      <td>3</td>\n",
       "      <td>864</td>\n",
       "      <td>864</td>\n",
       "      <td>864</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>819</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>824</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>825</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>825</td>\n",
       "      <td>825</td>\n",
       "      <td>825</td>\n",
       "      <td>825</td>\n",
       "      <td>825</td>\n",
       "      <td>825</td>\n",
       "      <td>825</td>\n",
       "      <td>825</td>\n",
       "      <td>832</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>859</td>\n",
       "      <td>859</td>\n",
       "      <td>859</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>813</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>813</td>\n",
       "      <td>813</td>\n",
       "      <td>813</td>\n",
       "      <td>813</td>\n",
       "      <td>813</td>\n",
       "      <td>813</td>\n",
       "      <td>813</td>\n",
       "      <td>813</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>868</td>\n",
       "      <td>868</td>\n",
       "      <td>868</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>821</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "      <td>828</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>866</td>\n",
       "      <td>866</td>\n",
       "      <td>866</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>819</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>819</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Attention Button  \\\n",
       "Subject Run                                                               \n",
       "0       0          2709          2709            2709                14   \n",
       "        1          3534          3534            3534                 7   \n",
       "        2          3194          3194            3194                 9   \n",
       "        3          4332          4332            4332                 5   \n",
       "        4          4221          4221            4221                10   \n",
       "...                 ...           ...             ...               ...   \n",
       "327     3           864           864             864                 5   \n",
       "        4           872           872             872                 7   \n",
       "        5           859           859             859                 6   \n",
       "        6           868           868             868                 7   \n",
       "        7           866           866             866                 7   \n",
       "\n",
       "             Attention Level  Attention Probe  Attention Reaction Time (s)  \\\n",
       "Subject Run                                                                  \n",
       "0       0                160               14                           14   \n",
       "        1                160                7                            7   \n",
       "        2                160                9                            9   \n",
       "        3                160                5                            5   \n",
       "        4                160               10                           10   \n",
       "...                      ...              ...                          ...   \n",
       "327     3                 40                5                            5   \n",
       "        4                 40                7                            7   \n",
       "        5                 40                6                            6   \n",
       "        6                 40                7                            7   \n",
       "        7                 40                7                            7   \n",
       "\n",
       "             Behavior_Image_Start  Category  Cue Validity  ...  righteye  \\\n",
       "Subject Run                                                ...             \n",
       "0       0                    2535       160            14  ...      2535   \n",
       "        1                    3367       160             7  ...      3367   \n",
       "        2                    3025       160             9  ...      3025   \n",
       "        3                    4167       160             5  ...      4167   \n",
       "        4                    4051       160            10  ...      4051   \n",
       "...                           ...       ...           ...  ...       ...   \n",
       "327     3                     819        40             5  ...       819   \n",
       "        4                     825        40             7  ...       825   \n",
       "        5                     813        40             6  ...       813   \n",
       "        6                     821        40             7  ...       821   \n",
       "        7                     819        40             7  ...       819   \n",
       "\n",
       "             state  time  timestamp  xRaw_lefteye  xRaw_righteye  \\\n",
       "Subject Run                                                        \n",
       "0       0     2535  2535       2535          2535           2535   \n",
       "        1     3367  3367       3367          3367           3367   \n",
       "        2     3025  3025       3025          3025           3025   \n",
       "        3     4167  4167       4167          4167           4167   \n",
       "        4     4051  4051       4051          4051           4051   \n",
       "...            ...   ...        ...           ...            ...   \n",
       "327     3      819   819        819           819            819   \n",
       "        4      825   825        825           825            825   \n",
       "        5      813   813        813           813            813   \n",
       "        6      821   821        821           821            821   \n",
       "        7      819   819        819           819            819   \n",
       "\n",
       "             yRaw_lefteye  yRaw_righteye  gaze_from_center  \\\n",
       "Subject Run                                                  \n",
       "0       0            2535           2535              2539   \n",
       "        1            3367           3367              3374   \n",
       "        2            3025           3025              3030   \n",
       "        3            4167           4167              4172   \n",
       "        4            4051           4051              4060   \n",
       "...                   ...            ...               ...   \n",
       "327     3             819            819               824   \n",
       "        4             825            825               832   \n",
       "        5             813            813               819   \n",
       "        6             821            821               828   \n",
       "        7             819            819               826   \n",
       "\n",
       "             gaze_towards_cued_side  \n",
       "Subject Run                          \n",
       "0       0                      2539  \n",
       "        1                      3374  \n",
       "        2                      3030  \n",
       "        3                      4172  \n",
       "        4                      4060  \n",
       "...                             ...  \n",
       "327     3                       824  \n",
       "        4                       832  \n",
       "        5                       819  \n",
       "        6                       828  \n",
       "        7                       826  \n",
       "\n",
       "[336 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['Subject','Run']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['UniqueID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.groupby(['Experiment','Group']).count()#['UniqueID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Behavioral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Add cued category from last presentation trial to memory blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each memory trial, add which category was last cued before that memory trial began\n",
    "\n",
    "# KZ: to do this correctly, do it using the last cued from full behavioral df\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "\n",
    "# for s in data['UniqueID'].unique():\n",
    "# # for each participant\n",
    "\n",
    "#     for r in data['Run'].unique():\n",
    "#     # for each run in this participant\n",
    "    \n",
    "#         data.loc[(data['Run']==r) \n",
    "#                  & (data['UniqueID']==s) \n",
    "#                  & (data['Trial Type']=='Memory'), 'Last Cued'] = data[(data['Run']==r) & (data['UniqueID']==s) & (data['Trial Type']=='Presentation') & (data['Trial']==9)]['Cued Category'].item()\n",
    "        \n",
    "# # make a copy of the data where novel images labeled by whether they are in the last-cued image category\n",
    "\n",
    "# data_nov = data\n",
    "# data     = add_nov_label(data, column_name = 'Last Cued')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are all of the statistical tests done on the behavioral data, roughly in the order they appear in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reaction Time Stats (Cued vs. Uncued side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure sides are corrected exp2 group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp : /sustain\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unequal length arrays",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f98b90ab6e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exp : '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     print(scipy.stats.ttest_rel(dat[dat['Cue Validity']==1]['Attention Reaction Time (s)'], \n\u001b[0;32m---> 11\u001b[0;31m                                 dat[dat['Cue Validity']==0]['Attention Reaction Time (s)']))\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mttest_rel\u001b[0;34m(a, b, axis, nan_policy)\u001b[0m\n\u001b[1;32m   5348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5350\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unequal length arrays'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5352\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unequal length arrays"
     ]
    }
   ],
   "source": [
    "# compare average attention probe reaction times (valid versus invalid)\n",
    "\n",
    "data_gr = data.groupby(['UniqueID','Cue Validity', 'Experiment'], as_index=False).mean()\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "\n",
    "    dat = data_gr[(data_gr['Experiment']== experiment)]\n",
    "\n",
    "    print('exp : '+ experiment)\n",
    "    print(scipy.stats.ttest_rel(dat[dat['Cue Validity']==1]['Attention Reaction Time (s)'], \n",
    "                                dat[dat['Cue Validity']==0]['Attention Reaction Time (s)']))\n",
    "\n",
    "    print()\n",
    "\n",
    "#         print(cohen_d(list(data_gr[(data_gr['Cue Validity']==1) & (data_gr['Experiment'] == experiment)]['Attention Reaction Time (s)']),\n",
    "#                       list(data_gr[(data_gr['Cue Validity']==0) & (data_gr['Experiment'] == experiment)]['Attention Reaction Time (s)'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = sb.barplot(data=data_gr, x='Experiment', y='Attention Reaction Time (s)', hue='Cue Validity')                               \n",
    "p.set_title('Attn Probe Reaction Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = sb.barplot(data=data_gr[data_gr['Experiment']=='/sustain'], x='Group', y='Attention Reaction Time (s)', hue='Cue Validity')                               \n",
    "p.set_title('Sustained Attention Task')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = sb.barplot(data=data_gr[data_gr['Experiment']=='/variabl'], x='Group', y='Attention Reaction Time (s)', hue='Cue Validity')             \n",
    "p.set_title('Variable Attention Task')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT Diff Comparison\n",
      "Ttest_indResult(statistic=nan, pvalue=nan)\n"
     ]
    }
   ],
   "source": [
    "diffs = {}\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "    \n",
    "    diffs[experiment] = []\n",
    "    d = data_gr[(data_gr['Experiment']== experiment)]\n",
    "\n",
    "    #diffs = {'Experiment_1':[], 'Experiment_2':[]}\n",
    "    #for d,label in zip([exp1, exp2],['Experiment_1', 'Experiment_2']):\n",
    "    \n",
    "    for s in d['Subject'].unique():\n",
    "        cued   = d[(d['Subject']==s)&(d['Cue Validity']==0)]['Attention Reaction Time (s)'].mean()\n",
    "        uncued = d[(d['Subject']==s)&(d['Cue Validity']==1)]['Attention Reaction Time (s)'].mean()\n",
    "\n",
    "        diffs[experiment].append(cued - uncued)\n",
    "\n",
    "print('RT Diff Comparison')\n",
    "print(scipy.stats.ttest_ind(diffs['/sustain'], diffs['/variabl']))\n",
    "#print(cohen_d(diffs['/sustain'], diffs['/variabl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Fully Attended images to all other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "experiment : /sustain\n",
      "Ttest_relResult(statistic=13.421183052640375, pvalue=1.3945182924068942e-19)\n",
      "\n",
      "\n",
      "experiment : /variabl\n",
      "Ttest_relResult(statistic=12.405867076386683, pvalue=3.6567724184869514e-17)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare average ratings for fully attended images to all other image types \n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "    \n",
    "    Fulls  = []\n",
    "    Others = []\n",
    "\n",
    "    for s in data[(data['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        Fulls.append(data[(data['UniqueID']==s)&(data['Attention Level']=='Full') & (data['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "        Others.append(data[(data['UniqueID']==s)&(data['Attention Level']!='Full') & (data['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "\n",
    "    print()\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(Fulls, Others))\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face versus Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "experiment : /sustain\n",
      "Ttest_relResult(statistic=7.687873877550006, pvalue=1.8473338043613615e-10)\n",
      "\n",
      "\n",
      "experiment : /variabl\n",
      "Ttest_relResult(statistic=7.085593793199018, pvalue=3.6138893528986493e-09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare ratings for fully attended scenes with ratings for fully attended faves\n",
    "\n",
    "f_p = data.groupby(['UniqueID', 'Experiment', 'Attention Level', 'Category'], as_index=False).mean()\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "        print()\n",
    "\n",
    "        print('experiment : '+experiment)\n",
    "\n",
    "        print(scipy.stats.ttest_rel(f_p[(f_p['Category']=='Place') & (f_p['Attention Level']=='Full') \n",
    "                                        & (f_p['Experiment']==experiment)]['Familiarity Rating'], \n",
    "\n",
    "                                    f_p[(f_p['Category']=='Face') & (f_p['Attention Level']=='Full') \n",
    "                                        & (f_p['Experiment']==experiment)]['Familiarity Rating']))\n",
    "\n",
    "        print ()\n",
    "    \n",
    "            \n",
    "#             print(cohen_d(f_p[(f_p['Category']=='Place') & (f_p['Attention Level']=='Full')& (f_p['Experiment']==experiment) & (f_p['Group']==group)]['Familiarity Rating'], \n",
    "#                                 f_p[(f_p['Category']=='Face') & (f_p['Attention Level']=='Full')& (f_p['Experiment']==experiment) & (f_p['Group']==group)]['Familiarity Rating']))\n",
    "#             print()\n",
    "\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attended Category versus Unattended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment : /sustain\n",
      "Ttest_relResult(statistic=7.169020123474894, pvalue=1.399590794698868e-09)\n",
      "\n",
      "experiment : /variabl\n",
      "Ttest_relResult(statistic=0.4310799396268719, pvalue=0.6681920627291599)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    Cats  = []\n",
    "    Nones = []\n",
    "\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        Cats.append(d[(d['UniqueID']==s) & (d['Attention Level'].isin(['Category']) & (d['Experiment']==experiment))]['Familiarity Rating'].mean())\n",
    "        Nones.append(d[(d['UniqueID']==s) & (d['Attention Level']=='None') & (d['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "\n",
    "\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(Cats, Nones))\n",
    "    #print(cohen_d(Cats, Nones))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attended Side vs Unattended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=4.320885072719229, pvalue=6.048927164309282e-05)\n",
      "\n",
      "Ttest_relResult(statistic=2.5918457744677217, pvalue=0.012363373090488588)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    Sides  = []\n",
    "    Nones = []\n",
    "\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        Sides.append(d[(d['UniqueID']==s) & (d['Attention Level'].isin(['Side'])) & (d['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "        Nones.append(d[(d['UniqueID']==s) & (d['Attention Level']=='None') & (d['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "\n",
    "    print(scipy.stats.ttest_rel(Sides, Nones))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sustained attention experiment\n",
    "\n",
    "# sb.barplot(data=data[data['Experiment']=='/sustain'], x='Attention Level', y='Familiarity Rating', hue='Group',\n",
    "#           order=['Full','Category','Nov_Cued','Side','None','Nov_Un'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable attention experiment\n",
    "\n",
    "# sb.barplot(data=data[data['Experiment']=='/variabl'], x='Attention Level', y='Familiarity Rating', hue='Group',\n",
    "#           order=['Full','Category','Nov_Cued','Side','None','Nov_Un'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cued versus Uncued Novel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "    \n",
    "    a = d[(d['Attention Level']=='Nov_Cued') & (d['Experiment']==experiment)]['Familiarity Rating']\n",
    "    b = d[(d['Attention Level']=='Nov_Un') & (d['Experiment']==experiment)]['Familiarity Rating']\n",
    "\n",
    "    #print('experiment : '+experiment+', Group : '+str(group))\n",
    "    print(experiment)\n",
    "    print(scipy.stats.ttest_rel(a, b))\n",
    "\n",
    "    #print(cohen_d(a, b))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature boost versus feature bias boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    cat_no   = []\n",
    "    nov_diff = []\n",
    "\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        cat = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Category', 'Full']))& (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        no = d[(d['UniqueID']==s) &(d['Attention Level']=='None')& (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        nov_c = d[(d['UniqueID']==s) &(d['Attention Level']=='Nov_Cued')& (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        nov_u = d[(d['UniqueID']==s) &(d['Attention Level']=='Nov_Un')& (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "\n",
    "        cat_no.append(cat - no)\n",
    "        nov_diff.append(nov_c - nov_u)\n",
    "\n",
    "\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(cat_no, nov_diff))\n",
    "    #print(cohen_d(cat_no, nov_diff))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature boost versus Location boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOWN BELOW:\n",
    "\n",
    "# mean(Cat & Full) - mean(None)\n",
    "# versus\n",
    "# mean(Side & Full) - mean(None)\n",
    "\n",
    "# -------------------------------\n",
    "# NOT YET REPLICATED IN NEW DATA:\n",
    "\n",
    "# Experiment 1: ( (mean(Cat & Full) - mean(None))  -    (mean(Side & Full) - mean(None)) )    \n",
    "# versus\n",
    "# Experiment 2: ( (mean(Cat & Full) - mean(None))   -    (mean(Side & Full) - mean(None)) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "\n",
    "full = {}; diffs = {}; side_diffs = {}\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    label = experiment \n",
    "\n",
    "    cat_nov  = []\n",
    "    side_nov = []\n",
    "\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        side = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Side','Full'])) & (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        cat  = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Category', 'Full'])) & (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        nov  = d[(d['UniqueID']==s)&(d['Attention Level']=='None') & (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "\n",
    "        cat_nov.append(cat - nov)\n",
    "        side_nov.append(side - nov)\n",
    "\n",
    "    print()\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(cat_nov, side_nov))\n",
    "    print()\n",
    "    \n",
    "    diff = [x-y for x,y in zip(cat_nov,side_nov)]\n",
    "    diffs[label] = diff\n",
    "    side_diffs[label] = side_nov\n",
    "    \n",
    "print()\n",
    "print('Feature boost relative to Location boost, Exp1 vs Exp 2')\n",
    "print(scipy.stats.ttest_ind(diffs['/sustain'], diffs['/variabl']))\n",
    "# print(cohen_d(diffs['/sustain'], diffs['/variabl']))\n",
    "print()\n",
    "print('Location boost relative to novel, Exp2 vs Exp1')\n",
    "print(scipy.stats.ttest_ind(side_diffs['/sustain'], side_diffs['/variabl']))\n",
    "# print(cohen_d(side_diffs['/sustain'], side_diffs['/variabl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Attended versus Side Attended boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "\n",
    "full = {}\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    label = experiment \n",
    "\n",
    "    cat_nov  = []\n",
    "    side_nov = []\n",
    "\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        side = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Side']))&(d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        cat  = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Full']))&(d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        nov  = d[(d['UniqueID']==s)&(d['Attention Level']=='None')&(d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "\n",
    "        cat_nov.append(cat - nov)\n",
    "        side_nov.append(side - nov)\n",
    "\n",
    "\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(cat_nov, side_nov))\n",
    "    # print(cohen_d(cat_nov, side_nov))\n",
    "    print()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_original.groupby(['Attention Level']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOT PARAMS\n",
    "snoop = 0\n",
    "stat_dict_full = {'/sustain':{}, '/variabl':{}}\n",
    "\n",
    "# color list \n",
    "col = ['r','orange','tan','purple','blue','grey']\n",
    "\n",
    "# cat list\n",
    "cats = ['Full','Category','Side','None']\n",
    "\n",
    "# plot settings\n",
    "sb.set_style(\"white\")\n",
    "plt.grid(False)\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)\n",
    "plt.xlabel('Attention Level',    fontsize = 20)\n",
    "plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "\n",
    "# for each experiment, for each test group, group and plot\n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "    \n",
    "        \n",
    "    label = experiment \n",
    "\n",
    "    d = data_original[(data_original['Experiment']==experiment)]\n",
    "\n",
    "\n",
    "    # VIOLIN PLOT\n",
    "    data = d.groupby(['UniqueID','Attention Level', 'Category'], as_index = False).mean()\n",
    "    print(label + ': Average Familiarity by Attention Level')\n",
    "    sb_plot = sb.violinplot(x='Attention Level', y='Familiarity Rating', \n",
    "                 data = data, split=True, hue='Category', \n",
    "                 order=cats)\n",
    "    sb_plot.set(ylim=(.2, 9))\n",
    "    ax1 = sb_plot.axes\n",
    "\n",
    "\n",
    "    ### SIGNIFICANCE STARS FOR PLOTTING ###\n",
    "    t_draw = {}\n",
    "\n",
    "#     for c in data['Attention Level'].unique():\n",
    "# #             if c in(['Nov_Cued','Nov_Un']) and label=='Experiment_2':\n",
    "\n",
    "# #                 # if comparing novel images from exp2, eliminate participant 28 (all Place-cued as last cued category)\n",
    "# #                 first  = list(data[(data['Attention Level']==c) & (data['Category']=='Face') & (data['UniqueID']!=28)]['Familiarity Rating'])\n",
    "# #                 second = list(data[(data['Attention Level']==c) & (data['Category']=='Place') & (data['UniqueID']!=28)]['Familiarity Rating'])\n",
    "\n",
    "# #             else:\n",
    "#         first  = list(data[(data['Attention Level']==c) & (data['Category']=='Face')]['Familiarity Rating'])\n",
    "#         second = list(data[(data['Attention Level']==c) & (data['Category']=='Place')]['Familiarity Rating'])\n",
    "\n",
    "#         t = scipy.stats.ttest_rel(first, second)\n",
    "\n",
    "#         if t[1]<.001:\n",
    "#             t_draw[c] = '***'\n",
    "\n",
    "#         elif t[1]<.01:\n",
    "#             t_draw[c] = '**'\n",
    "\n",
    "#         elif t[1]<.05:\n",
    "#             t_draw[c] = '*'\n",
    "\n",
    "#         elif t[1]<.0551:\n",
    "#             t_draw[c] = '+'\n",
    "\n",
    "\n",
    "    ### SIGNIFICANCE BETWEEN VIOLINS FOR PLOTTING ###\n",
    "    stat_dict = {}\n",
    "    k = data.groupby(['UniqueID','Attention Level'],as_index=False).mean()\n",
    "\n",
    "    for pair in list(itertools.combinations(cats, r=2)):\n",
    "        t = stats.ttest_rel(k[k['Attention Level']==pair[0]]['Familiarity Rating'], \n",
    "                            k[k['Attention Level']==pair[1]]['Familiarity Rating'])\n",
    "        \n",
    "        stat_dict_full[label][pair] = {'t': t.statistic, 'p': t.pvalue}\n",
    "\n",
    "        # dictionary where every key is a pair categories with a difference that has p value less than .0551\n",
    "        if t[1]<=.0551:\n",
    "            stat_dict[pair] = {'t': t.statistic, 'p': t.pvalue}\n",
    "\n",
    "\n",
    "    ### CREATE AND ADD SIGNIFICANCE LINES TO PLOT ###\n",
    "    for relationship in  ['pos','neg']:\n",
    "\n",
    "        plotted_cats = []\n",
    "        to_be_plotted = []\n",
    "        line_height = 0\n",
    "\n",
    "        # FOR EACH CATEGORY\n",
    "        for idx,c in enumerate(cats):\n",
    "\n",
    "            x = sig_bars(c, cats, stat_dict, sign=relationship)\n",
    "            # get all significance lines from this category to every other category\n",
    "\n",
    "            for idx,line in enumerate(x):\n",
    "            # for each line from this category to another category (starting with the nearest category)\n",
    "\n",
    "                if (line['categories'] not in plotted_cats) and (line!=np.nan) and (type(line['categories'])!=float):\n",
    "                # if there is a difference in the correct direction (pos/neg) and it has not been plotted yet\n",
    "\n",
    "                    line['y'] = line['y'] + line_height\n",
    "                    # assign the next available height to this line \n",
    "                    # (give its height a boost based on how many lines have been plotted already)\n",
    "\n",
    "                    to_be_plotted.append(line)\n",
    "                    # append this line to the list of lines to be plotted\n",
    "\n",
    "                    plotted_cats.append(line['categories'])\n",
    "                    # add this category pair to the list of category pairs that has been plotted\n",
    "\n",
    "                    # CONTINUE THE CASCADE OF LINES\n",
    "                    # now, start from the category we have just drawn a line to\n",
    "                    # and loop through the rest of the categories from there\n",
    "\n",
    "                    # first, give the line a new name so we can loop over new lines, without losing our first one\n",
    "                    b = line\n",
    "\n",
    "                    # as long as there is difference in the correct direction (pos/neg) \n",
    "                    # between the most recent category and the next one\n",
    "                    while b['next']!= 0 :\n",
    "\n",
    "                        # grab the first category for the line between them\n",
    "                        first_cat = b['categories'][0]\n",
    "\n",
    "                        # then get the line STARTING from the category we have just drawn a line to, to the NEXT category it differs from\n",
    "                        b = sig_bars(b['next'], cats, stat_dict, sign=relationship)[0]\n",
    "\n",
    "                        # if there is a difference in the correct direction (pos/neg) that has not been plotted yet\n",
    "                        if (b['categories'] not in plotted_cats) and (b != np.nan) and (type(b['categories'])!=float):\n",
    "\n",
    "                            # adjust its height so it is the same height as the line that brought us here\n",
    "                            b['y'] = b['y'] + line_height\n",
    "\n",
    "                            # add this line to the lines we will plot\n",
    "                            to_be_plotted.append(b)\n",
    "\n",
    "                            # add this category pair to the list of pairs that's been plotted\n",
    "                            plotted_cats.append(b['categories'])\n",
    "\n",
    "                            # also add the pair of categories containing the original starting category and this ending category\n",
    "                            # (so that doesn't get plotted redundantly)\n",
    "                            plotted_cats.append((line['categories'][0], b['categories'][1]))\n",
    "\n",
    "                            # AND add the relationship from the original starting category to this starting category\n",
    "                            # (so that doesn't get plotted redundantly)\n",
    "                            plotted_cats.append((first_cat, b['categories'][1]))\n",
    "\n",
    "                    line_height = line_height - .4\n",
    "                    # adjust height next lines will be drawn at\n",
    "\n",
    "        # Plot the lines\n",
    "        for each in to_be_plotted:\n",
    "\n",
    "            if relationship == 'pos':\n",
    "                ax1.axhline(each['y'], ls='-', xmin = each['x_min'], xmax = each['x_max'], \n",
    "                    linewidth = each['width'], color = col[cats.index(each['categories'][0])])\n",
    "\n",
    "            if relationship == 'neg':\n",
    "                ax1.axhline(each['y']-2, ls='-', xmin = each['x_min'], xmax = each['x_max'], \n",
    "                    linewidth = each['width'], color = col[-cats.index(each['categories'][1])])\n",
    "\n",
    "    # Plot the stars\n",
    "    for stars in t_draw:\n",
    "        ax1.text((cats.index(stars)), 4.5, t_draw[stars], horizontalalignment='center', size='large', color='black')\n",
    "\n",
    "    # save figure\n",
    "    snoop +=1\n",
    "    stat_dict_full[label][pair] = {'t': t.statistic, 'p': t.pvalue}\n",
    "    if snoop ==2:\n",
    "        plt.savefig(\"violindoo.pdf\")\n",
    "\n",
    "    # show figure\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timecourse Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_window(combo, window_length):\n",
    "    '''\n",
    "    input:  dataframe of behavioral data from an entire experiment\n",
    "    output: dataframe of same shape where raw values have been replaced by rolling window mean\n",
    "    '''\n",
    "\n",
    "    # select data from memory runs\n",
    "    data = combo[combo['Trial Type']=='Memory'][['Attention Level','Familiarity Rating','Trial','UniqueID','Run']]\n",
    "\n",
    "    # re-structure the data - each row is a trial, each column is an attn level\n",
    "    df = data.pivot_table(index=['UniqueID', 'Trial'], columns='Attention Level', values='Familiarity Rating')\n",
    "\n",
    "    # apply rolling window, for each subject\n",
    "    window_data = df.groupby(['UniqueID']).apply(lambda x: x.rolling(window_length, min_periods=1, center=True).mean())\n",
    "\n",
    "    return(window_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combo = data_original[data_original['Group']==2]\n",
    "\n",
    "# # select data from memory runs\n",
    "# data = combo[combo['Trial Type']=='Memory'][['Attention Level','Familiarity Rating','Trial','UniqueID','Run']]\n",
    "\n",
    "# # re-structure the data - each row is a trial, each column is an attn level\n",
    "# df = data.pivot_table(index=['UniqueID', 'Trial'], columns='Attention Level', values='Familiarity Rating')\n",
    "\n",
    "# # apply rolling window, for each subject\n",
    "# window_data = df.groupby(['UniqueID']).apply(lambda x: x.rolling(window_length, min_periods=1, center=True).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "    \n",
    "# Apply sliding window\n",
    "\n",
    "window_length = 20\n",
    "\n",
    "exp1_mean_window = apply_window(data_original[(data_original['Experiment']=='/sustain')], window_length)\n",
    "exp2_mean_window = apply_window(data_original[(data_original['Experiment']=='/variabl')], window_length)\n",
    "print('finish')\n",
    "\n",
    "# end up with two dictionaries (one for each exp) each containing two keys ( for groups 1 & 2) \n",
    "\n",
    "    \n",
    "for data,label in zip([exp1_mean_window, exp2_mean_window], ['sust', 'var']):\n",
    "\n",
    "    plot_data[label] = {}\n",
    "\n",
    "    #for key in data.keys():\n",
    "\n",
    "    # average across all trials within each subject\n",
    "    group = data.reset_index().groupby(['UniqueID','Trial']).mean()\n",
    "\n",
    "    # melt/restructure the data\n",
    "    group_melt = pd.melt(group.reset_index(), id_vars=['UniqueID','Trial'], value_vars=['Category', 'Full','None','Nov_Un', 'Nov_Cued','Side'])\n",
    "\n",
    "    # assign data to dictionary key\n",
    "    plot_data[label] = group_melt\n",
    "\n",
    "    # plotting color key\n",
    "    palette = sb.color_palette(\"RdBu\", 20)\n",
    "\n",
    "    \n",
    "          \n",
    "# for data in [exp1_mean_window, exp2_mean_window]:\n",
    "\n",
    "#     plot_data = {}\n",
    "\n",
    "#     for key in data.keys():\n",
    "\n",
    "#         # average across all trials within each subject\n",
    "#         group = data.reset_index().groupby(['UniqueID','Trial']).mean()\n",
    "\n",
    "#         # melt/restructure the data\n",
    "#         group_melt = pd.melt(group.reset_index(), id_vars=['UniqueID','Trial'], value_vars=['Category', 'Full','None','Nov_Un', 'Nov_Cued','Side'])\n",
    "\n",
    "#         # assign data to dictionary key\n",
    "#         plot_data[key] = group_melt\n",
    "\n",
    "#     # plotting color key\n",
    "#     palette = sb.color_palette(\"RdBu\", 20)\n",
    "#     # Cued category    -->  warm colors \n",
    "#     # Uncued category  -->  cool colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sb.color_palette(\"RdBu\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2d5e07609cdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_data' is not defined"
     ]
    }
   ],
   "source": [
    "plot_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window - Familiarity Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window - Novel Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sust Sliding Window - Novel Images Only\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Attention Level'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-01397428bba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# plot data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Attention Level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nov_Un'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Nov_Cued'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# ci=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n\u001b[1;32m     15\u001b[0m                             \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13]})\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Attention Level'"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ' Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "    # plot data\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Nov_Un','Nov_Cued'])], # ci=None,\n",
    "                palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13]})\n",
    "    ax.set(ylim=(1.3, 2.3))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xlabel('Memory Trial')\n",
    "    plt.ylabel('Familiarity')\n",
    "\n",
    "    # ttest at each timepoint ######################\n",
    "    ttest_data = timepoint_ttest(data, ['Nov_Cued','Nov_Un'])\n",
    "\n",
    "    # add lines where pvalue is significant\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Nov_Un') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.41, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[13])\n",
    "            plt.axhline( y=1.4, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[5])\n",
    "\n",
    "        plt.axhline( y=1.41, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[13])\n",
    "        plt.axhline( y=1.4, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[5])\n",
    "        # plt.axvline(x, .1, .3, color='red')\n",
    "\n",
    "    plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "    plt.savefig(label+\"novel_time.pdf\")\n",
    "    plt.show()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel Image Difference Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sust Group : Sliding Window - Novel Images Only\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-02800870778f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# exp = plot_data[key][label]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrial_avs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trial'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Attention Level'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'UniqueID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrial_avs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nov_Diffs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "\n",
    "    print(key + ' Group : Sliding Window - Novel Images Only')\n",
    "\n",
    "    # exp = plot_data[key][label]\n",
    "\n",
    "    trial_avs = plot_data[key].groupby(['Trial','Attention Level','UniqueID'], as_index=False).mean()\n",
    "    trial_avs['Nov_Diffs'] = np.nan\n",
    "\n",
    "    for s in trial_avs['UniqueID'].unique():\n",
    "        for t in trial_avs['Trial'].unique():\n",
    "\n",
    "            first  = trial_avs[(trial_avs['Attention Level']=='Nov_Cued') \n",
    "                               & (trial_avs['Trial']==t)\n",
    "                              & (trial_avs['UniqueID']==s)]['value'].item()\n",
    "\n",
    "            second = trial_avs[(trial_avs['Attention Level']=='Nov_Un'  ) \n",
    "                               & (trial_avs['Trial']==t)\n",
    "                              & (trial_avs['UniqueID']==s)]['value'].item()\n",
    "\n",
    "            difference = first - second\n",
    "\n",
    "            trial_avs.loc[(trial_avs['Trial']==t) & (trial_avs['UniqueID']==s),'Nov_Diffs'] = first - second\n",
    "\n",
    "    ax = sb.lineplot(x='Trial', y='Nov_Diffs', data=trial_avs)\n",
    "    ax.set(ylim=(-.1, .4))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    sb.regplot(x=\"Trial\", y=\"Nov_Diffs\", data=trial_avs, scatter=False)\n",
    "\n",
    "    trial_av_grp = trial_avs.groupby(['Trial'], as_index=False).mean()\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(trial_avs['Trial'], trial_avs['Nov_Diffs'])\n",
    "\n",
    "    print('slope = ' + str(slope))\n",
    "    print('intercept = ' + str(intercept))\n",
    "    print('p_value = ' + str(p_value))\n",
    "    print()\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xlabel('Memory Trial')\n",
    "    plt.ylabel('Familiarity Difference')\n",
    "    # plt.savefig(exp+\"_novel_diff.pdf\")\n",
    "\n",
    "    #print(exp)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncued Category images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sust: Sliding Window - Novel Images Only\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Attention Level'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d292c491ca70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# plot data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Attention Level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Side'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Nov_Un'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# ci=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n\u001b[1;32m     15\u001b[0m                             \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], 'Novel':'black'}) \n",
      "\u001b[0;31mKeyError\u001b[0m: 'Attention Level'"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "    # plot data\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Side','None','Nov_Un'])], # ci=None,\n",
    "                    palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], 'Novel':'black'}) \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.set(ylim=(1.2, 2.8))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "\n",
    "    # stats test\n",
    "    data = data[data['Attention Level'].isin(['Side','None','Nov_Un'])]\n",
    "\n",
    "    #ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Side','Nov_Un'])#, related=False)\n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Nov_Un') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "\n",
    "    for x in ranges(index):\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[19])\n",
    "            plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[13])\n",
    "\n",
    "        else:\n",
    "            plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[19])\n",
    "            plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[13])\n",
    "\n",
    "\n",
    "        # ttest at each timepoint #################\n",
    "        ttest_data = timepoint_ttest(data, ['Side','None'])\n",
    "\n",
    "        # lines w/ sig pval #######################\n",
    "        index = ttest_data[(ttest_data['Attention Level']=='Side') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "        index = set(index)\n",
    "\n",
    "        for x in ranges(index):\n",
    "            if x[0] == x[1]:\n",
    "                x_new_0 = x[0]-.1\n",
    "                x_new_1 = x[1]+.1\n",
    "\n",
    "                plt.axhline( y=1.42, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[19])\n",
    "                plt.axhline( y=1.4, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[16])\n",
    "\n",
    "            else:\n",
    "                plt.axhline( y=1.42, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[19])\n",
    "                plt.axhline( y=1.4, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[16])\n",
    "\n",
    "        # ttest at each timepoint #################\n",
    "        ttest_data = timepoint_ttest(data, ['Nov_Un','None'])#, related=False)\n",
    "\n",
    "        # lines w/ sig pval #######################\n",
    "        index = ttest_data[(ttest_data['Attention Level']=='Nov_Un') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "        index = set(index)\n",
    "\n",
    "        for x in ranges(index):\n",
    "\n",
    "            if x[0] == x[1]:\n",
    "                x_new_0 = x[0]-.1\n",
    "                x_new_1 = x[1]+.1\n",
    "\n",
    "                plt.axhline( y=1.52, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[16])\n",
    "                plt.axhline( y=1.5, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[13])\n",
    "\n",
    "            else:\n",
    "                plt.axhline( y=1.52, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[16])\n",
    "                plt.axhline( y=1.5, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[13])\n",
    "\n",
    "\n",
    "        plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "        plt.savefig(label+\"_uncued_categories.pdf\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window - Images in Cued Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sust: Sliding Window - Novel Images Only\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Attention Level'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-228756d6c42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# plot ####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Attention Level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Full'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Nov_Cued'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 'Category', # ci=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n\u001b[1;32m     15\u001b[0m                             \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], \"Novel\":\"black\"})\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Attention Level'"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "    # plot ####################################\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Full', 'Nov_Cued', 'Category'])], # 'Category', # ci=None,\n",
    "                    palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], \"Novel\":\"black\"})\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.set(ylim=(1.25, 2.75))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    #ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Category','Nov_Cued'])#, related=False)    \n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Nov_Cued') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[3])\n",
    "            plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[5])\n",
    "\n",
    "        plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[3])\n",
    "        plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[5])\n",
    "\n",
    "\n",
    "    # ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Category','Full'])\n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Category') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.52, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[0])\n",
    "            plt.axhline( y=1.5, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[3])\n",
    "\n",
    "\n",
    "        plt.axhline( y=1.52, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[0])\n",
    "        plt.axhline( y=1.5, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[3])\n",
    "\n",
    "\n",
    "    # ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Nov_Cued','Full'])\n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Full') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.42, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[0])\n",
    "            plt.axhline( y=1.4, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[5])\n",
    "\n",
    "        plt.axhline( y=1.42, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[0])\n",
    "        plt.axhline( y=1.4, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[5])\n",
    "\n",
    "    # plot settings & save ####################\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "    plt.savefig(label+\"cued_categories.pdf\")\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_nov' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-655810aaa60e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_nov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_nov' is not defined"
     ]
    }
   ],
   "source": [
    "data_nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The following 'value_vars' are not present in the DataFrame: ['Nov_Cued', 'Nov_Un']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-049b91a47e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# melt/restructure the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mgroup_melt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UniqueID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Full'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Nov_Un'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Nov_Cued'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Side'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# assign data to dictionary key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/reshape/melt.py\u001b[0m in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;34m\"The following 'value_vars' are not present in\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;34m\" the DataFrame: {missing}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 )\n\u001b[1;32m     76\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_vars\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The following 'value_vars' are not present in the DataFrame: ['Nov_Cued', 'Nov_Un']\""
     ]
    }
   ],
   "source": [
    "# Apply sliding window\n",
    "window_length = 20\n",
    "\n",
    "plot_data = {}\n",
    "    \n",
    "# Apply sliding window\n",
    "\n",
    "window_length = 20\n",
    "\n",
    "exp1_mean_window = apply_window(data_original[(data_original['Experiment']=='/sustain')], window_length)\n",
    "exp2_mean_window = apply_window(data_original[(data_original['Experiment']=='/variabl')], window_length)\n",
    "print('finish')\n",
    "\n",
    "# end up with two dictionaries (one for each exp) each containing two keys ( for groups 1 & 2) \n",
    "\n",
    "        \n",
    "for data,label in zip([exp1_mean_window, exp2_mean_window], ['sust', 'var']):\n",
    "\n",
    "    plot_data[label] = {}\n",
    "\n",
    "    #for key in data.keys():\n",
    "\n",
    "    # average across all trials within each subject\n",
    "    group = data.reset_index().groupby(['UniqueID','Trial']).mean()\n",
    "\n",
    "    # melt/restructure the data\n",
    "    group_melt = pd.melt(group.reset_index(), id_vars=['UniqueID','Trial'], value_vars=['Category', 'Full','None','Nov_Un', 'Nov_Cued','Side'])\n",
    "\n",
    "    # assign data to dictionary key\n",
    "    plot_data[label] = group_melt\n",
    "\n",
    "    # plotting color key\n",
    "    palette = sb.color_palette(\"RdBu\", 20)\n",
    "    # Cued category    -->  warm colors \n",
    "    # Uncued category  -->  cool colors\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# # Apply sliding window\n",
    "# window_length = 20\n",
    "\n",
    "# exp1_nov_mean_window = apply_window(data_nov['/sustain'], window_length)\n",
    "# exp2_nov_mean_window = apply_window(data_nov['/variabl'], window_length)\n",
    "\n",
    "# # prepare data for plotting\n",
    "# plot_data_nov={}\n",
    "\n",
    "# for data,key in zip([exp1_nov_mean_window, exp2_nov_mean_window],['exp1','exp2']):\n",
    "    \n",
    "#     # average across all trials within each subject\n",
    "#     group = data.reset_index().groupby(['Subject','Trial']).mean()\n",
    "    \n",
    "#     # melt/restructure the data\n",
    "#     group_melt = pd.melt(group.reset_index(), id_vars=['Subject','Trial'], \n",
    "#                          value_vars=['Category', 'Full','None','Novel','Side'])\n",
    "    \n",
    "#     # assign data to dictionary key\n",
    "#     plot_data_nov[key] = group_melt\n",
    "    \n",
    "# # plotting color key\n",
    "# palette = sb.color_palette(\"RdBu\", 20)\n",
    "# # Cued category    -->  warm colors \n",
    "# # Uncued category  -->  cool colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_data_nov['exp1']['Attention Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "\n",
    "# sb.set_style(\"white\")\n",
    "\n",
    "# for key in plot_data.keys():\n",
    "    \n",
    "#     for label in ['1','2']:\n",
    "    \n",
    "#         print(key + ' Group '+ label + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "#         data = plot_data[key][label]\n",
    "    \n",
    "#         # plot ####################################\n",
    "#         ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "#                     data = data[data['Attention Level'].isin(['Full', 'Novel', 'Category'])], # 'Category', # ci=None,\n",
    "#                         palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "#                                 \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], \"Novel\":\"black\"})\n",
    "\n",
    "#         plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#         ax.set(ylim=(1.25, 2.75))\n",
    "#         ax.set(xlim=(0, 39))\n",
    "\n",
    "#         #ttest at each timepoint #################\n",
    "#         ttest_data = timepoint_ttest(data, ['Category','Novel'])#, related=False)    \n",
    "\n",
    "#         # lines w/ sig pval #######################\n",
    "#         index = ttest_data[(ttest_data['Attention Level']=='Novel') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "#         index = set(index)\n",
    "\n",
    "#         for x in ranges(index):\n",
    "\n",
    "#             if x[0] == x[1]:\n",
    "#                 x_new_0 = x[0]-.1\n",
    "#                 x_new_1 = x[1]+.1\n",
    "\n",
    "#                 plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[3])\n",
    "#                 plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[5])\n",
    "\n",
    "#             plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[3])\n",
    "#             plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[5])\n",
    "\n",
    "\n",
    "#         # ttest at each timepoint #################\n",
    "#         ttest_data = timepoint_ttest(data, ['Category','Full'])\n",
    "\n",
    "#         # lines w/ sig pval #######################\n",
    "#         index = ttest_data[(ttest_data['Attention Level']=='Category') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "#         index = set(index)\n",
    "\n",
    "#         for x in ranges(index):\n",
    "\n",
    "#             if x[0] == x[1]:\n",
    "#                 x_new_0 = x[0]-.1\n",
    "#                 x_new_1 = x[1]+.1\n",
    "\n",
    "#                 plt.axhline( y=1.52, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[0])\n",
    "#                 plt.axhline( y=1.5, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[3])\n",
    "\n",
    "\n",
    "#             plt.axhline( y=1.52, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[0])\n",
    "#             plt.axhline( y=1.5, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[3])\n",
    "\n",
    "\n",
    "#         # ttest at each timepoint #################\n",
    "#         ttest_data = timepoint_ttest(data, ['Novel','Full'])\n",
    "\n",
    "#         # lines w/ sig pval #######################\n",
    "#         index = ttest_data[(ttest_data['Attention Level']=='Full') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "#         index = set(index)\n",
    "\n",
    "#         for x in ranges(index):\n",
    "\n",
    "#             if x[0] == x[1]:\n",
    "#                 x_new_0 = x[0]-.1\n",
    "#                 x_new_1 = x[1]+.1\n",
    "\n",
    "#                 plt.axhline( y=1.42, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[0])\n",
    "#                 plt.axhline( y=1.4, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[5])\n",
    "\n",
    "#             plt.axhline( y=1.42, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[0])\n",
    "#             plt.axhline( y=1.4, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[5])\n",
    "\n",
    "#         # plot settings & save ####################\n",
    "#         plt.grid(False)\n",
    "#         plt.rc('xtick', labelsize=15)\n",
    "#         plt.rc('ytick', labelsize=15)\n",
    "#         plt.xlabel('Attention Level',    fontsize = 20)\n",
    "#         plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "#         plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "#         plt.savefig(label+\"cued_categories.pdf\")\n",
    "\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb.set_style(\"white\")\n",
    "\n",
    "# for key,label in zip(plot_data_nov.keys(),['Experiment 1','Experiment 2']):\n",
    "    \n",
    "#     print(label + ': Sliding Window - Uncued Category Images')\n",
    "    \n",
    "#     data = plot_data_nov[key]\n",
    "    \n",
    "#     # plot data\n",
    "#     ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "#                 data = data[data['Attention Level'].isin(['Side','None','Novel'])], # ci=None,\n",
    "#                     palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "#                             \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], 'Novel':'black'}) \n",
    "#     plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#     ax.set(ylim=(1.2, 2.8))\n",
    "#     ax.set(xlim=(0, 39))\n",
    "\n",
    "    \n",
    "#     # stats test\n",
    "#     data = data[data['Attention Level'].isin(['Side','None','Novel'])]\n",
    "    \n",
    "#     #ttest at each timepoint #################\n",
    "#     ttest_data = timepoint_ttest(data, ['Side','Novel'])#, related=False)\n",
    "    \n",
    "#     # lines w/ sig pval #######################\n",
    "#     index = ttest_data[(ttest_data['Attention Level']=='Novel') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "#     index = set(index)\n",
    "    \n",
    "    \n",
    "#     for x in ranges(index):\n",
    "#         if x[0] == x[1]:\n",
    "#             x_new_0 = x[0]-.1\n",
    "#             x_new_1 = x[1]+.1\n",
    "\n",
    "#             plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[19])\n",
    "#             plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[13])\n",
    "                        \n",
    "#         else:\n",
    "#             plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[19])\n",
    "#             plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[13])\n",
    "        \n",
    "        \n",
    "#     # ttest at each timepoint #################\n",
    "#     ttest_data = timepoint_ttest(data, ['Side','None'])\n",
    "    \n",
    "#     # lines w/ sig pval #######################\n",
    "#     index = ttest_data[(ttest_data['Attention Level']=='Side') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "#     index = set(index)\n",
    "    \n",
    "#     for x in ranges(index):\n",
    "#         if x[0] == x[1]:\n",
    "#             x_new_0 = x[0]-.1\n",
    "#             x_new_1 = x[1]+.1\n",
    "\n",
    "#             plt.axhline( y=1.42, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[19])\n",
    "#             plt.axhline( y=1.4, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[16])\n",
    "            \n",
    "#         else:\n",
    "#             plt.axhline( y=1.42, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[19])\n",
    "#             plt.axhline( y=1.4, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[16])\n",
    "        \n",
    "#     # ttest at each timepoint #################\n",
    "#     ttest_data = timepoint_ttest(data, ['Novel','None'])#, related=False)\n",
    "    \n",
    "#     # lines w/ sig pval #######################\n",
    "#     index = ttest_data[(ttest_data['Attention Level']=='Novel') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "#     index = set(index)\n",
    "    \n",
    "#     for x in ranges(index):\n",
    "        \n",
    "#         if x[0] == x[1]:\n",
    "#             x_new_0 = x[0]-.1\n",
    "#             x_new_1 = x[1]+.1\n",
    "\n",
    "#             plt.axhline( y=1.52, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[16])\n",
    "#             plt.axhline( y=1.5, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[13])\n",
    "    \n",
    "#         else:\n",
    "#             plt.axhline( y=1.52, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[16])\n",
    "#             plt.axhline( y=1.5, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[13])\n",
    "\n",
    "        \n",
    "#     plt.xticks([0, 9, 19, 29, 39])\n",
    "    \n",
    "#     plt.savefig(label+\"_uncued_categories.pdf\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images in Cued Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "\n",
    "    # plot ####################################\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Full', 'Side'])], # 'Category', # ci=None,\n",
    "                    palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], \"Novel\":\"black\"})\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.set(ylim=(1.25, 2.75))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    #ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Full','Side'])#, related=False)\n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Side') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[0])\n",
    "            plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[19])\n",
    "\n",
    "        plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[0])\n",
    "        plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[19])\n",
    "\n",
    "\n",
    "    # plot settings & save ####################\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "    plt.savefig(label+\"_cued_location.pdf\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images in Uncued Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "    # plot ####################################\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Category', 'None'])], # 'Category', # ci=None,\n",
    "                    palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], \"Novel\":\"black\"})\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.set(ylim=(1.25, 2.75))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    #ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Category','None'])#, related=False)    \n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Category') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[3])\n",
    "            plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[16])\n",
    "\n",
    "        plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[3])\n",
    "        plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[16])\n",
    "\n",
    "\n",
    "\n",
    "    # plot settings & save ####################\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "    plt.savefig(label+\"_uncued_location.pdf\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaze = pd.read_csv('../parsed_data/full_gaze.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaze.groupby(['Experiment','Group']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
